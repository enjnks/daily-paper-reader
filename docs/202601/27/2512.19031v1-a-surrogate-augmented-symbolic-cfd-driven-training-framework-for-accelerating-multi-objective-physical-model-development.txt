Title: A Surrogate-Augmented Symbolic CFD-Driven Training Framework for Accelerating Multi-objective Physical Model Development

URL Source: https://arxiv.org/pdf/2512.19031v1

Published Time: Tue, 23 Dec 2025 03:11:55 GMT

Number of Pages: 40

Markdown Content:
# Graphical Abstract 

A Surrogate-Augmented Symbolic CFD-Driven Training Frame-work for Accelerating Multi-objective Physical Model Develop-ment 

Yuan Fang, Fabian Waschkowski, Maximilian Reissmann, Richard D. Sand-berg, Takuo Oda, Koichi Tanimoto c.11 Inputs mapping c.2 Surrogate modelling c.3 Candidate model 

selection for CFD 

reevaluation 

c.12 Source of surrogate refinement 

Colonies 

ð‘“ ! = ð‘ ! ð¼ " âˆ’ ð¼ # + (ð¼ # âˆ’ ð‘ #)

ð‘“ # = ð¼ "ð¼ # + ð¼ # âˆ’ ð‘ "

ð‘“ " = ð‘ $ ð½ " + ð½ # (ð½ # âˆ’ ð‘ %)

â‹¯

ð‘“ ! = ð‘ ! ð¼ " âˆ’ ð¼ # + (ð¼ # âˆ’ ð‘ #)

ð‘“ # = ð¼ "ð¼ # + ð¼ # âˆ’ ð‘ "

ð‘“ " = ð‘ $ ð½ " + ð½ # (ð½ # âˆ’ ð‘ %)

â‹¯

â‹¯

Train 

Refine 

Colonies 

ð‘“ ! = ð‘ # âˆ’ ð¼ # ð¼ " âˆ’ ð¼ #

ð‘“ # = ð‘ !ð¼ # âˆ’ ð‘ "ð¼ "

ð‘“ " = ð‘ $ ð½ # âˆ’ ð½ " (ð½ " âˆ’ ð‘ !)

ð‘“ ! = ð¼ " ð¼ " + ð¼ # âˆ’ ð‘ #

ð‘“ # = ð¼ "ð¼ # âˆ’ ð‘ "ð¼ # âˆ’ ð‘ $

ð‘“ " = ð‘ $ð½ #ð½ " (ð½ # + ð‘ %)

â‹¯

â‹¯

â‹¯

# +

RANS DNS 

Errors from CFD reevaluation 

Selection Criteria: 

1: Large uncertainty region 

2: Minimum error 

> arXiv:2512.19031v1 [cs.LG] 22 Dec 2025

# Highlights 

A Surrogate-Augmented Symbolic CFD-Driven Training Frame-work for Accelerating Multi-objective Physical Model Develop-ment 

Yuan Fang, Fabian Waschkowski, Maximilian Reissmann, Richard D. Sand-berg, Takuo Oda, Koichi Tanimoto 

â€¢ Integrated surrogate modeling into a symbolic-regression CFD-driven training framework for physical-model development 

â€¢ Verified the frameworkâ€™s robustness across varied hyperparameter set-tings and flow cases involving turbulence alone or coupled with heat flux. A Surrogate-Augmented Symbolic CFD-Driven Training Framework for Accelerating Multi-objective Physical Model Development 

Yuan Fang a,1, âˆ—, Fabian Waschkowski a,1 , Maximilian Reissmann a, Richard D. Sandberg a, Takuo Oda b, Koichi Tanimoto b

> aDepartment of Mechanical Engineering, University of Melbourne, Parkville, Melbourne, 3010, VIC, Australia
> bResearch and Innovation Centre Takasago Area, Mitsubishi Heavy Industries, Ltd,., 2 Chome-1 Araicho Shinhama, Takasago, 676-0008, Hyogo, Japan

Abstract 

Computational Fluid Dynamics (CFD)-driven training, which combines ma-chine learning (ML) techniques with fluid dynamics software that provides CFD feedback, has shown great potential for developing implementable and physically consistent closure models with improved accuracy compared to conventional baseline models. In the original CFD-driven training frame-work, each ML-generated candidate model is embedded in a CFD solver, and its performance is evaluated by comparing computed quantities of in-terest against reference data. However, exploring optimal models requires hundreds to thousands of CFD evaluations, resulting in prohibitive training costs for complex industrial flows, where a single CFD calculation can al-ready be computationally expensive. To address this limitation, we propose an extended framework that, for the first time, integrates surrogate modeling into symbolic CFD-driven training in real time, aiming to reduce the over-all training cost. The surrogate model learns to approximate the errors of the ML-generated models based on previous CFD evaluations, and this surro-gate mapping is continuously refined throughout the training process. Newly generated models are first assessed by the surrogate. Only those predicted to yield small errors or high uncertainty are subsequently re-evaluated with full CFD computations. Specifically, the generated discrete expressions from 

> âˆ—Corresponding author:fang.y5@unimelb.edu.au
> 1These authors contributed equally to this work.

symbolic regression are mapped into a continuous space using the averaged values of the input symbols as inputs to the probabilistic surrogate model. To accommodate multi-objective model training, particularly in situations where assigning fixed weights to competing quantities is challenging, the surrogate model is further generalized to multi-output settings. This is achieved by extending the kernel function to a matrix form, enabling one mean and vari-ance prediction per training objective. Based on these probabilistic outputs, various selection metrics and thresholds are evaluated to identify the optimal setup. The proposed surrogate-augmented CFD-driven training framework is developed and demonstrated across a range of cases, encompassing statis-tically one- and two-dimensional flows, as well as single-expression (targeting only the turbulence model) and multi-expression (simultaneous optimization of both turbulence and heat-flux models). Across all cases, the framework achieves a substantial reduction in training cost while the resulting models maintain comparable predictive accuracy to those obtained with the original CFD-driven approach. 

Keywords: Surrogate modeling, Machine learning, Turbulence modeling, Heat flux modeling, Gaussian Processes 

1. Introduction 

Among the various efforts to incorporate machine learning (ML) into physical model development, Computational Fluid Dynamics (CFD)-driven training has demonstrated remarkable and continuing success [1, 2, 3]. In this approach, ML algorithms are directly coupled with CFD solvers, so that each ML-generated candidate model is embedded in the solver and evaluated via full CFD calculations. The CFD outputs are then used to compute the cost function, which serves as feedback to the ML algorithm. The training process continues iteratively until the cost function converges to a predefined threshold or the maximum number of iterations is reached. This tight in-tegration offers two advantages: Firstly, the trained models exhibit strong robustness and physical consistency, since they are validated within the CFD solver rather than merely fitted to post-processed training goals [4]. Secondly, the cost function can be flexibly defined in terms of quantities of engineer-ing interest beyond the closure terms themselves, allowing the model to be trained to target any physically meaningful flow quantities that can be ex-tracted from the CFD solution. These advantages enable the development 2of turbulence [1, 2], heat flux [5], transition [6] models in Reynolds-Averaged Navier-Stokes (RANS) calculations, or LES sub-grid-scale [7] and wall [8] models using only limited reference data, thus even sparse experimental data can be employed for model training. Extensions to the CFD-driven training framework have enabled the de-velopment of physical models for increasingly complex flow scenarios, but have also increased training costs. Waschkowski [3] developed two such func-tionalities, named multi-expression and multi-objective training. The for-mer allows multiple models that interactively affect the final flow prediction, such as coupled transition and turbulence modeling [6] or joint heat flux and turbulence modeling [9], to be trained simultaneously. The latter en-ables consideration of multiple quantities of interest in constructing the cost function without predefining their relative weights, thereby avoiding bias in the optimization process [6, 10]. Moreover, to improve the generalizability of ML-trained models, multi-case training has been proposed to train mod-els across multiple flow cases with varying geometries and operation condi-tions [11]. Although these extensions significantly expand the applicability of CFD-driven training to complex and realistic problems, they also enlarge the search space, thereby increasing training costs. For example, if the ML al-gorithm initially generates 100 candidate models and subsequently updates 50 models in each of the following 100 training iterations, assuming that one CFD evaluation requires one core hour, the total computational cost amounts to (100 + 50 Ã— 99) Ã— 1 = 5 , 050 core hours. This severely limits the applicability of the CFD-driven training framework to more complex, industry-related cases, such as unsteady, three-dimensional, or multiphase flows, where even a single CFD calculation is computationally expensive. Therefore, the extremely high training cost remains a significant barrier to the broader application of CFD-driven training. To mitigate this prohibitive computational cost, this study introduces sur-rogate modeling into the CFD-driven training framework. Surrogate mod-eling techniques have demonstrated great potential in design optimization problems [12, 13, 14], uncertainty quantification [15, 16] and inverse modeling [17, 18], where they effectively bridge the gap between limited high-fidelity data and low-fidelity predictions. For CFD-driven training, the surrogate model is designed to exploit the wealth of information contained in previ-ously generated models, including those with relatively large errors that are typically discarded, and to leverage this information to reduce training cost. It is expected that as the training progresses, many candidate models become 3fine-tuned and share similar structures and comparable performance, mak-ing full CFD evaluations for all of them unnecessary and computationally expensive. Surrogate modeling, which constructs a computationally efficient approximation of a complex and expensive system using data from a lim-ited number of prior evaluations, therefore naturally fits this problem. By learning from accumulated CFD results from earlier training and continu-ously refining itself during subsequent iterations, the surrogate model can predict the performance of most newly generated candidates, allowing full CFD evaluations to be reserved for those with high potential or considerable uncertainty. This integration is expected to reduce overall training costs while maintaining substantial predictive accuracy. Various surrogate modeling approaches have been proposed in the liter-ature. Traditional polynomial response surface models approximate the sys-tem response using low-order polynomials in the input variables; however, they suffer from the curse of dimensionality, as the number of polynomial terms grows with the number of inputs. This often leads to overfitting and limits their capability to capture complex nonlinear relationships [19, 20]. Radial basis function (RBF) models, on the other hand, offer good interpo-lation properties through localized basis functions, but are highly sensitive to kernel parameters [21]. Other machine-learning-based surrogates, such as artificial neural networks (ANNs) [22], support vector regression (SVR) [23], and random forests [24], can learn complex nonlinear and high-dimensional mappings but generally lack interpretability. In contrast, Gaussian Process (GP) modeling provides a probabilistic and interpretable framework for surrogate construction and is adopted in this study because of its simplicity, flexibility, and ability to quantify uncer-tainty [25]. A GP can be viewed as a generalization of a Gaussian probability distribution to functions, where any finite collection of function values follows a multivariate Gaussian distribution characterized by a mean vector and a covariance matrix. The predictive mean gives the estimated output (e.g., the cost function value), while the predictive variance quantifies the associ-ated uncertainty and naturally reflects confidence in each prediction. This property makes GPs particularly suitable for the present problem, where the surrogate model predicts both the cost function value and its confidence interval for each candidate model. Consequently, only models predicted to have very small errors or large uncertainty are re-evaluated using full CFD simulations, thereby significantly accelerating the overall training process. In this study, the GP-based surrogate modeling technique is integrated 4into our existing CFD-driven training framework [3]. The proposed frame-work, referred to as the surrogate-augmented CFD-driven training frame-work, extends the original CFD-driven training framework, and these two terms will be used throughout this paper. After the first training gener-ation, the candidate models and their corresponding errors obtained from CFD evaluations are used to train the surrogate model. In subsequent gen-erations, only the candidate models predicted by the surrogate to have very small errors or considerable uncertainty are re-evaluated through full CFD simulations. The updated results from these evaluations are then incorpo-rated as additional data to refine the surrogate model. In this manner, the surrogate model evolves concurrently with the CFD-driven training, continu-ously improving its predictive capability. Further methodological details are provided in Section sec:methodology. This paper is organized as follows. Section 2 describes the establishment of the surrogate modeling framework for physical model development, its coupling with the existing symbolic-regression-based CFD-driven training framework, and the extension to multi-objective surrogate-based training. Section 3 introduces the physical model closures and flow cases employed in this study. Section 4 presents the comparison of training efficiency between the regular and surrogate-augmented CFD-driven training frameworks, along with the explicit model expressions and performance evaluations. Finally, Section 5 provides the conclusions and outlines future perspectives. 

2. Methodology 

The methodology section is organized into two main parts. The first part describes the integration of surrogate modeling into the current CFD-driven training framework, detailing each component, including the input parame-ters, the surrogate modeling algorithm, and the corresponding outputs. The second part introduces the physical closure models derived from ML training, along with descriptions of all the test cases used in this study. 

2.1. Surrogate Modeling Implementation 

Figure 1 illustrates the surrogate-augmented CFD-driven training frame-work, where the components of the regular CFD-driven framework [1, 3] are shown in black, and the newly developed surrogate modeling components are highlighted in red. The model training process begins with regular CFD-driven training, followed by the introduction of the surrogate modeling algo-5(b) Candidate  

> Models
> (e)Error
> (a) Symbolic
> Regression

â€¦ML CFD        

> update
> evaluate
> RANS
> ith generation
> (c) Surrogate
> modelling (d)
> RANS RANS RANS
> update
> c.11
> c.12
> c.2 c.3 Figure 1: Surroate-augmented CFD-driven training framework Newly introduced com-ponents relative to the previous framework are highlighted in red, while elements retained from the original framework are shown in grey. Grey boxes outlined with black dashed lines indicate RANS simulations that are skipped (not executed) and replaced by surrogate predictions.

rithm in subsequent training iterations. This design is necessary because, in the initial iteration, no candidate models nor corresponding error data are yet available for training the surrogate model. For each generation, the symbolic regression ML method (in this study, GEP) generates candidate models, as shown in Figures 1 (a). These models in Figure 1 (b) are then used as inputs to the surrogate model in Figure 1 (c), which predicts both the expected er-ror and the associated uncertainty range for each model. Only those models predicted to yield minor errors or exhibit large uncertainty are selected for CFD re-evaluation, as illustrated in Figure 1 (d). The re-evaluated models, together with their actual CFD errors, are subsequently used to refine the surrogate model. Meanwhile, the combined information from the surrogate predictions and CFD evaluations is fed back to GEP in Figure 1 (a) to guide further model evolution. This iterative training process continues until either the model error falls below a prescribed threshold or the maximum number of training iterations is reached. In the following subsections, each component relevant to the surrogate modeling development is discussed in detail. 

2.1.1. Inputs mapping 

The input to the surrogate modeling is the output from the GEP approach â€” the candidate models that are represented as distinct character strings, as shown in Figure 1. These strings possess no inherent notion of smooth change between each other; in other words, they are discrete in nature. However, the surrogate model used in this study is based on Gaussian processes, which 6c.11 Inputs mapping c.2 Surrogate modelling c.3 Candidate model 

selection for CFD 

reevaluation 

c.12 Source of surrogate refinement 

Colonies                        

> ð‘“ !=ð‘ !ð¼ "âˆ’ð¼ #+(ð¼ #âˆ’ð‘ #)
> ð‘“ #=ð¼ "ð¼ #+ð¼ #âˆ’ð‘ "
> ð‘“ "=ð‘ $ð½ "+ð½ #(ð½ #âˆ’ð‘ %)

â‹¯                       

> ð‘“ !=ð‘ !ð¼ "âˆ’ð¼ #+(ð¼ #âˆ’ð‘ #)
> ð‘“ #=ð¼ "ð¼ #+ð¼ #âˆ’ð‘ "
> ð‘“ "=ð‘ $ð½ "+ð½ #(ð½ #âˆ’ð‘ %)

â‹¯

â‹¯

Train 

Refine 

Colonies                                      

> ð‘“ !=ð‘ #âˆ’ð¼ #ð¼ "âˆ’ð¼ #
> ð‘“ #=ð‘ !ð¼ #âˆ’ð‘ "ð¼ "
> ð‘“ "=ð‘ $ð½ #âˆ’ð½ "(ð½ "âˆ’ð‘ !)
> ð‘“ !=ð¼ "ð¼ "+ð¼ #âˆ’ð‘ #
> ð‘“ #=ð¼ "ð¼ #âˆ’ð‘ "ð¼ #âˆ’ð‘ $
> ð‘“ "=ð‘ $ð½ #ð½ "(ð½ #+ð‘ %)

â‹¯

â‹¯

â‹¯

# +

RANS DNS 

> Errors from CFD reevaluation
> Selection Criteria:
> 1: Large uncertainty region
> 2: Minimum error

Figure 2: Main components of the surrogate model framework integrated into CFD-driven closure training 

typically operate on continuous spaces, where closeness in the input space implies correlation in the output. Therefore, the discrete inputs generated by the GEP must first be mapped into a continuous representation, as illustrated in Figure 2 (c.11), before being fed into the surrogate modeling algorithm. The mapping is required to represent the similarity between the generated models through their relative distances in a continuous space. We now describe the procedure for transforming a discrete symbolic ex-pression into a continuous representation, followed by a description of how these high-dimensional embeddings are projected onto a lower-dimensional manifold to extract semantically relevant information. The detailed imple-mentation of this process is presented in Algorithm 1. 7Algorithm 1 Mapping symbolic phenotypes to a continuous low-dimensional representation 

Require: Phenotype expressions {fk}nk=1 , input values (from base line model calculation) {I, J}mi=1 

Ensure: Mapped phenotype expressions {h(fk)}nk=1  

> 1:

for f âˆˆ { fk}nk=1 do  

> 2:

for I, J âˆˆ { I, J}mi=1 do  

> 3:

yi = f (I, J ) â–· Point-wise model evaluation 

end for  

> 4:

y = 1

> m

P 

> i

yi â–· Dimensional reduction via aggregation  

> 5:

{h(f )}i â† y â–· Append to return value 

end for 

With each model population, a list of expressions, each expression (sim-plified phenotype representation) is evaluated pointwise on a dataset (steps 1-3). Specifically, the GEP framework constructs a model equation by as-sembling symbols from a predefined set, e.g., S = Ii, I 2, +, âˆ’, Ã— into a list referred to as the genotype. For example: 

Ã— + I1 I1 I2 (1) represents a genotype that the GEP algorithm decodes into an expression tree (via depth-first pre-order traversal), which can be interpreted as the corre-sponding phenotype equation, i.e. (I1 + I1) Ã— I2 for Equation 1. This expres-sion is utilized because altering a single symbol in the genotype can substan-tially alter the resulting phenotypeâ€”and, consequently, the CFD simulation results and model error. For instance, changing Equation 1 to Ã— Ã— I1 I1 I2

modifies the phenotype from 2I1 Ã—I2 to I21 Ã—I2. Conversely, another genotype such as Ã— I2 + I1 I1 differs syntactically from Equation 1 but encodes the same phenotype. Hence, phenotype-based strings are selected for subsequent processing and simplified to remove redundancy. Up to this point, the phenotype-based input strings remain high-dimensional. Each symbol is represented using one-hot encoding, where a symbol set of size 

N is expressed as an N -dimensional vector with a value of 1 at the position corresponding to the active symbol and zero elsewhere. Steps 2â€“4 describe how this information is projected into a lower-dimensional, more learnable space for the surrogate model. In Step 2, the values of input symbols, such as Ii, are extracted from baseline model calculations, as high-fidelity exper-imental or simulation datasets are often unavailable for complex, industry-8relevant flows. In Step 3, the corresponding values of the generated models at the same locations are computed. In Step 4, an aggregation function h(y)

is applied to reduce the model predictions to a low-dimensional representa-tion; here, the mean model prediction is used. Consequently, each generated model corresponds to a single point in the continuous space, as illustrated in Figure 2 (c.11). 

2.1.2. Algorithm and the hyperparameters 

The task of the surrogate modeling algorithm is, given the mapped input values of a candidate model, to predict its corresponding error and quantify the uncertainty of this prediction, as illustrated in Figure 2 (c.2). Gaussian Processes (GPs) provide these quantities through the mean Î¼ and variance 

Ïƒ2. Specifically, a GP represents realizations of a random function as a vector of random variables following a multivariate Gaussian distribution characterized by a mean vector Î¼ and a covariance matrix Î£. Specifying these two quantities defines the GP and establishes a prior distribution over functions. For the mean function Î¼(x), a zero-mean assumption is commonly adopted, implying that the expected value of the random function over all sample functions at a specific point is zero. Consequently, the covariance function 

Î£( x, x â€²), also referred to as the kernel of the GP, governs the correlations between function values and thereby defines the prior distribution over func-tions. By combining this prior with the available training data through Bayesâ€™ theorem, a posterior distribution is obtained that captures both the data trends and predictive uncertainty. The essential step in constructing a GP model, therefore, is to specify an appropriate kernel function. Once the kernel is defined, no explicit parameter learning is required, which is why GPs are regarded as nonparametric models. The kernel function examined in this work is the Rational Quadratic (RQ) kernel: 

Î£( x, x â€²

) = Ïƒ2



1 + âˆ¥x âˆ’ xâ€²

âˆ¥2

2Î±â„“ 2

âˆ’Î±

(2) which introduces an additional shape parameter Î±, resulting in the hyperpa-rameter set Î¸ = Ïƒ, â„“, Î± . The parameter Î± controls the extent to which the effective length scale â„“ varies, allowing the RQ kernel to model functions with different degrees of smoothness across the input space. 9The above hyperparameters are determined by maximizing the logarith-mic marginal likelihood of the observed data, p (y|X, Î¸ ), defined as 

Î¸âˆ— = argmax Î¸log p (y|X, Î¸ ) (3) where X denotes the input data points and y represents the corresponding model outputs. To enable multi-objective optimization within the surrogate-augmented CFD-driven training framework, the surrogate model is extended to predict multiple output quantities. Specifically, for each training objective, the model provides one mean Î¼ and one variance prediction Ïƒ2. For a total of p outputs, the GP kernel is generalized to a matrix form as follows: 

Î£(x, x â€²) = 

ï£®ï£¯ï£°

Î£11 (x, x â€²) Â· Â· Â· Î£1p(x, x â€²)

... . . . ...

Î£p1(x, x â€²) Â· Â· Â· Î£pp (x, x â€²)

ï£¹ï£ºï£» (4) where the diagonal element Î£ii (x, x â€²

) represents the covariance function as-sociated with the ith training objective, where the off-diagonal elements 

Î£ij (x, x â€²

) ( iÌ¸ = j) describe the cross-covariances between different output fea-tures. Inference with multi-output GPs requires inverting the full covariance matrix that incorporates all n training samples, resulting in a matrix of size 

np Ã— np for p output features. Since matrix inversion scales cubically in time, 

O(n3p3), and quadratically in memory, O(n2p2), the computational cost can quickly become prohibitive. In the present study, we assume independence among the training objectives and set Î£ij (x, x â€²

) = 0 f or i Ì¸ = j.

2.1.3. Candidate Model Selection for CFD reevaluation 

The predicted mean Î¼ of the surrogate model approximates the true error values of the candidate models and replaces direct CFD evaluation. The variance Ïƒ2 from the surrogate model, on the other hand, represents the predictive uncertainty, and can be utilized in combination with the error estimates to identify the candidate models that require re-evaluation through CFD calculation, as shown in Figure 2 (c.3). The goal is to achieve the same minimum fitness values as in regular CFD-driven training while performing as few CFD evaluations as possible. Initially, a random population of models is generated by the GEP algo-rithm. Since no CFD-based error data are yet available to train the surrogate 10 Algorithm 2 Selection of candidate models for CFD re-evaluation 

Require: Training generation index n, model population P , and hyperpa-rameters H 

> 1:

if n = 0 then â–· No CFD data available to train the surrogate model  

> 2:

P0 â† errors from CFD predictions â–· Randomly initialize the starting population  

> 3:

else if n = 1 then  

> 4:

Psampled â† sample (m) â–· Resample m individuals uniformly from the population  

> 5:

else  

> 6:

Psampled â† selection metric â–· Select based on predicted mean errors and uncertainty levels  

> 7:

Psampled â† CFD evaluations  

> 8:

P \ Psampled â† surrogate model predictions â–· Only the selected models are re-evaluated using CFD model, all candidate models are evaluated using CFD simulations. In subse-quent training generations, once error information from the initial population becomes available, a uniform distribution of ni sampling points is generated. To ensure balanced sampling when the surrogate model has limited training data and low prediction accuracy, a nearest-neighbor search is performed to identify the model closest to each sampling point. A fixed number of ni mod-els is then selected for CFD re-evaluation, while the errors of the remaining models are predicted using the surrogate model. For all subsequent training generations, only candidate models that meet a predefined selection thresh-old based on a selection metric that combines surrogate-predicted error and uncertainty are re-evaluated by CFD. The remaining models are replaced by surrogate predictions, reducing computational cost while maintaining accu-racy. The key question that follows is: what selection metric and threshold should be used to determine which models undergo CFD re-evaluation? Three selection metrics were investigated and implemented, each assign-ing a selection value to each candidate model based on the surrogate modelâ€™s mean and variance predictions. The first metric considered is the Lower Confidence Bound (LCB) 

mLCB (x) = âˆ’Î¼(x) + Î²Ïƒ (x), (5) 11 which is defined as a linear combination of the predictive mean Î¼ and stan-dard deviation Ïƒ, weighted by a hyperparameter Î². A value of Î² = 0 corre-sponds to selecting candidates with the smallest predicted errors, whereas a larger Î² favors the selection of candidates that contribute most to reducing the predictive uncertainty. The second metric considered is Expected Improvement (EI), one of the most widely used selection criteria in the literature. The EI metric quanti-fies the expected improvement of a candidate model over the current best-performing solution, balancing exploitation of promising regions and explo-ration of uncertain areas predicted by the surrogate model. 

I(x) = max (0 , f (x+) âˆ’ Î¼(x)) , (6) where f (x+) denotes the error of the current best-performing candidate model in the population. The expected improvement can then be calculated as 

mEI (x) = ( f (x+)âˆ’Î¼(x)âˆ’Î¾)Î¦ 

f (x+) âˆ’ Î¼(x) âˆ’ Î¾Ïƒ(x)



+Ïƒ(x)Ï•

f (x+) âˆ’ Î¼(x) âˆ’ Î¾Ïƒ(x)



,

(7) where Î¦ and Ï• represent the cumulative distribution function and the proba-bility density function of a standard Gaussian distribution, respectively. The hyperparameter Î¾ is introduced to artificially reduce the improvement I(x),thereby encouraging exploration of regions with higher uncertainty. When assigning selection values based on the selection metric, an ad-ditional treatment is applied to exclude non-convergent models from being selected. In the regular CFD-driven training, divergent models are typically marked by assigning a large error value (e.g., 9999) to ensure they are ex-cluded from subsequent optimization rounds. In the present framework, a convergence weighting, denoted as mCW , is introduced to scale the selection values: 

mCW = min 



1, âˆ¥x âˆ’ xdiv âˆ¥

Î´âˆ¥xconv âˆ’ xdiv âˆ¥



, (8) where the convergence factor Î´ controls the onset of linear discounting. For example, when Î´ = 0 .5, the convergence weighting reaches unity for selection distances greater than 0.5âˆ¥xconv âˆ’ xdiv âˆ¥, while models located closer to the divergence boundary receive smaller weighting values. For multi-objective optimization, the selection value is computed sepa-rately for each output feature of every candidate model, following a proce-dure similar to that proposed by Jeong and Obayashi [26]. These individual 12 selection values are then integrated into a single scalar value per candidate using multi-objective optimization techniques. After assigning selection values based on the error and uncertainty pre-dicted by the surrogate model, selection thresholds must be defined to deter-mine which models are chosen for re-evaluation. In total, four thresholding strategies are implemented: 1. Fixed-number selection ( ms,f ) â€” selects a predefined number of models. 2. Relative-value selection ( ms,r ) â€” selects models whose normalized se-lection values exceed a specified relative threshold across the entire input space. 3. Pareto-front selection ( ms,p ) â€” used in multi-objective optimization to select only the models located on the assigned Pareto front. These thresholds can also be applied in combination. For example, specifying 

ms,f = 10 and ms,r = 0 .5 means that only ten models with normalized selection values greater than 0.5 are selected for CFD re-evaluation. 

2.2. Modeling strategy and description of flow cases 

This subsection first introduces the training objectives for the physical model development, together with the corresponding inputs and outputs. The developed framework is tested on both standalone turbulence-model training and coupled turbulence and heat-flux model training. Subsequently, the computational setup of the development and demonstration cases and the formulation of their associated cost functions are presented. The selected cases cover statistically one- and two-dimensional flows under a range of operating conditions. 

2.2.1. Turbulence and heat flux modeling 

The Boussinesq hypothesis used in the two-equation turbulence model (here, k âˆ’ Ï‰ SST) assumes that the Reynolds stress tensor Ï„ij is linear pro-portional to the deviatoric component of the mean strain rate Sâˆ— 

> ij

, an ap-proximation that oversimplifies the underlying physics in highly anisotropic and non-equilibrium flow regions. The objective here therefore, is to extend the linear model with the supplement proposed by Pope [27], i.e., with an 13 extra anisotropy as: 

Ï„ij = 23Ïk Î´ij 

| {z } 

> isotropy

âˆ’ 2Î¼T Sâˆ—

> ij

| {z } 

> anisotropy

+ 2Ïk aij 

| {z } 

> extra anisotropy

,

aij = g1V 1 

> ij

+ g2V 2 

> ij

+ g3V 3 

> ij

,gi=1 ,2,3 = f (A[1 : 5] , I 1, I 2, +, âˆ’, Ã—)

(9) Three tensor bases V 1 

> ij

= sij , V 2 

> ij

= sik wkj âˆ’ wik skj and V 3 

> ij

= sik skj âˆ’ 

> 13

Î´ij smn snm are adopted for statistically two-dimensional flows [27, 28]. I1 =

smn snm ; I2 = wmn wnm are two associated non-zero scalar invariants. In these definitions, sij = (1 /Ï‰ )Sâ€² 

> ij

and wij = (1 /Ï‰ )Î©ij denote non-dimensionalized strain and rotation rate tensors, respectively. The inputs for the turbulence model closure development include the constants A, two invariants I1, I 2 and a set of mathematical operators, while the outputs are the coefficients gi=1 ,2,3.An artificial turbulent production term, R, as introduced by [29], is trained alongside the additional anisotropic stress. This term adopts a struc-ture similar to the original turbulent production term, based on the observa-tion that the anisotropic stress correction alone is insufficient to achieve the desired model accuracy. 

R = 2 kb ij âˆ‚j Ui, (10) where bij (V kij , I k) = g4V 1 

> ij

+ g5V 2 

> ij

+ g6V 3 

> ij

.For heat-flux modeling, a modification to the standard gradient diffusion hypothesis (SGDH) is used as the training target. SDGH assumes that the wall-normal heat flux is proportional to the mean temperature gradient: 

uiÎ¸ = âˆ’Î±tâˆ‚iT, (11) Usually, Î±t = Î¼t/P r t represents the turbulent thermal diffusivity, modeled as the ratio of eddy viscosity Î¼t to a constant turbulent Prandtl number 

P r t = 0 .85 . The use of a constant turbulent Prandtl number implies that the turbulence isotropically diffuses heat - an assumption that often is incorrect and this work aims to improve upon. Therefore, here a function is trained to replace the constant 1/P r t as follows: 

uiÎ¸ = âˆ’Î±GEP Î¼tâˆ‚iT, Î±GEP = g(A[1 : 5] , I 1, I 2, J 1, J 2, J 3, J 4, J 5, +, âˆ’, Ã—) (12) 14 where Ji are temperature invariants. J1 = âˆ‚iT âˆ‚ iT, J 2 = âˆ‚iT S ij âˆ‚j T, J 3 =

âˆ‚iT S ij Sjk âˆ‚kT, J 4 = âˆ‚iT Î©ij Î©jk âˆ‚kT, J 5 = âˆ‚iT Î©ij Sjk âˆ‚kT . Therefore, the con-stants, velocity and temperature invariants, together with a set of mathemat-ical operators, serve as the inputs, while Î±GEP is the output for the heat-flux closure development. 

2.2.2. Setup of development and demonstration cases 

Once the mean error and uncertainty were obtained from the surrogate model predictions (see Figure 2 (c.2)), various combinations of model selec-tion metrics, their corresponding hyperparameters, and selection thresholds were explored during the methodology development phase, as described in Section 2.1.3. To identify the recommended setup for the surrogate-augmented CFD-driven framework, four flow cases are considered and grouped according to increasing levels of physical complexity and computation cost. Two develop-ment cases that are computationally inexpensive, allows for explore combi-nations of surrogate model hyperparameters to identify an optimal hyperpa-rameter set. They are a square duct flow, used for turbulence-model train-ing, and a vertical natural convection (VNC) case, used for turbulence and heat-flux model training. To assess the performance and robustness of the framework using the identified hyperparameter configuration, two additional demonstration cases are subsequently considered: a horizontal mixed convec-tion (HMC) configuration and a concentric horizontal annulus (CHA) case. These cases involve higher physical complexity and computational cost and therefore provide a evaluation of the frameworkâ€™s generality and robustness. For each flow case, the sources of the high-fidelity datasets, along with the corresponding RANS mesh configurations, numerical setups, and cost-function formulations, are presented in this subsection. The duct flow, shown in Figure 3, represents an internal flow with a rect-angular cross-section that typically develops mean secondary vortices in the duct corners. However, the RANS approach with the Boussinesq approxima-tion fails to capture these secondary flows, making this case a representative benchmark for turbulence model development. In the present training, the selected case is a square duct with an aspect ratio of 1 and a friction Reynolds number of Re Ï„ = 360 . RANS is performed in OpenFOAM v2306 using the incompressible steady-state solver simpleFoam. The computational domain is restricted to one quarter of the rectangular cross-section, with two no-slip walls and two symmetry boundaries applied, as illustrated in Figure 3 (a). 15 Genetic

operator evaluate   

> 0.2 0.4 0.6 0.8
> U

Encoding & Tokenization Optimization 

# 1. Acquisition 2. Pre-processing  

> ð‘¦
> ð‘§ (a) (b)
> ð‘¦
> ð‘§
> ð‘¥
> 0.5ð·
> ð·
> ð·
> 0.5ð· No slip wall
> Symmetry
> Main
> flow Figure 3: Schematic of the duct flow. (a) computational domain with boundary conditions; (b) mesh

The corresponding mesh configuration is shown in Figure 3 (b). The DNS reference data is from the work of Vinuesa et al. [30]. In the training setup, the objective is to determine the two coefficients gi(i = 1 , 2) in the additional anisotropic stress term aij in Equation 9, using two invariants Ii(i = 1 , 2) as inputs. Two cost functions extracted at y/h = 0 .5 are defined: one based on the second velocity component and the other on the third velocity com-ponent, with the aim of accurately capturing the secondary flow structures, shown in Table 1. A series of thermal convection cases is selected to evaluate the frame-workâ€™s performance in training coupled turbulence and heat-flux models. Statistically, one-dimensional vertical natural convection (VNC) and hori-zontal mixed convection (HMC) flows are employed as examples. Both VNC and HMC configurations involve fully developed planar channel flows con-fined between two parallel walls maintained at different temperatures. The flow is driven by buoyancy arising from the imposed temperature gradient, which introduces a strong coupling between the thermal and momentum fields. In the HMC case, an additional constant mean pressure gradient is applied, resulting in combined buoyancy- and shear-driven flow. Figure 4 illustrates the computational domains, meshes, and boundary conditions for the VNC and HMC simulations. The development VNC case corresponds to Ra = 5 .4 Ã— 10 5 and P r = 0 .709 , while the HMC case is characterized by 

Ra = 10 8, Re b = 10 ,000 , and P r = 1 . The RANS calculations are performed in OpenFOAM v2306 using a self-developed solver for the VNC case (see ?? )and the buoyantBoussinesqSimpleFoam solver for the HMC case. The high-fidelity datasets are obtained from direct numerical simulations (DNS), with 16 ð‘‡ ! 

> ð‘‡ "
> ð‘‡ !
> ð‘‡ "
> (a)
> ð‘¥
> ð‘‡ !
> ð‘‡ "
> ð‘”
> (b)
> ð‘¦
> ð‘¥
> (c) ð‘» ð’„
> ð‘» ð’‰
> ð‘” ð‘“ #
> ð‘¥
> ð‘¦
> ð‘§
> ð‘¤ð‘Žð‘™ð‘™
> ð‘¤ð‘Žð‘™ð‘™
> Periodic Periodic
> (d)
> ð‘¥
> ð‘¦ Figure 4: Schematic of the vertical natural and horizontal mixed convection flows. (a) and (c) computational domain with boundary conditions; (b) and (d) mesh

the VNC data from Ng et al.[31] and the HMC data from Pirozzoli et al.[32]. In the model training framework, the training objectives for the statistically one-dimensional VNC and HMC cases are the coefficients g1 in aij and g4 in 

bij with one invariant I1 used in the turbulence model, and Î±GEP with two invariants I1 and J1 used in the heat-flux model. The two cost functions are defined based on the mean velocity J(u) and mean temperature J(T ) profiles in Table 1. To advance toward a more realistic and complex configuration involving multiple coupled physical fields, natural convection of helium in a horizon-tal concentric annulus is selected. Unlike statistically one-dimensional flows, this configuration exhibits distinct flow structures at different angular po-sitions, making it a challenging benchmark for both multi-physics coupled modeling and surrogate modeling techniques. The case chosen corresponds to the highest Rayleigh number, Ra = 2 .38 Ã— 10 10 , available in the DNS ref-erence database of Li et al. [33], with a Prandtl number of Pr = 0.688. The three-dimensional geometric configuration is shown in Figure 5 (a), where the inner and outer cylinder radii are rin = 0 .26 and rout = 1 .26 , respectively, yielding an axial wall-to-wall distance of L = 1 . The mesh configuration is illustrated in Figure 5 (b), where only half of the concentric annulus is mod-eled. The curved surfaces are treated as no-slip walls maintained at different temperatures, while the centerline is assigned a symmetry boundary condi-tion. The RANS calculations are conducted in OpenFOAM v2306 using the 17 (a) (b)      

> Hot wall
> Cold wall
> Hot
> Cold
> !
> "
> #
> gravity
> Cold Wall
> Hot Wall
> Periodic
> Periodic
> ï¼ˆ2ï¼‰ï¼ˆ3ï¼‰Figure 5: Schematic of the horizontal concentric annulus of helium. (a) computational domain with boundary conditions; (b) mesh

Case Purposes Objectives Inputs Cost Function P r Ra 

Duct training aij Ii J(u1), J (u22 + u23) - -VNC training aij , R ij , u â€²T â€² Ii, J i J(u), J (T ) 0.709 5.4e5 HMC testing aij , R ij , u â€²T â€² Ii, J i J(u), J (T ) 1 10e8 CHA testing aij , u â€²T â€² Ii, J i, N i J(u180 ), J (u120 ) 0.688 2.38e10  

> Table 1: Training and testing flow cases for surrogate-augmented CFD-driven training framework

buoyantBoussinesqSimpleFoam solver. In the RANS closures training setup, the training goal is 4 expressions with 3 for gi(i = 1 , 2, 3) in aij in the turbu-lence model and 1 for Î±GEP in the heat-flux model. The inputs for the former is two invariants Ii(i = 1 , 2) and three extra input features Ni(i = 1 , 2, 3) 

inspired by the work of Ling et al. [34]. Specifically, they are selected to 

3. Results and Discussion 

This section presents the results for four studied casesâ€”square duct flow, VNC, HMC, and natural convection in a CHA. The discussion focuses on both the performance of the surrogate-augmented CFD-driven training frame-work compared with the regular CFD-driven approach, and the predictive performance of the trained models for each case. 18 Metric Î²/Î¾ ms,r ms,f ms,p ni mi,r          

> LCB 1.0,2.0,3.0, 5.0,6.0,8.0 0.1, 0.25, 0.5, 0.75, 0.9 -, 1, 2, 5 -,1,2 5,8,10,12,15 -, 0.5, 0.75 EI 0.01,0.05,0.1, 0.5,1.0,5.0 0.05,0.1,0.25, 0.5,0.75,0.9 -, 1, 2, 5 -,1,2 5,8,10,12,15 -, 0.5, 0.75 Table 2: Overview of selection metric, threshold and initial selection hyperparameters investigated via passive training method for the square duct flow

3.1. Development cases: Square duct and Vertical natural convection 3.1.1. Evaluation of Surrogate Model Performance 

As described in the Methodology section (2.1.3), multiple hyperparam-eters are involved in configuring the surrogate model. Using the duct and VNC training cases, we aim to identify the recommended configuration for the surrogate model setup. The investigation begins with square-duct flow, in which various combi-nations of hyperparameters are tested. Table 2 summarizes the investigated hyperparameters of the selection metrics and thresholds employed in the surrogate model to determine which candidate models are selected for CFD re-evaluation. After this analysis, the remaining two hyperparameters â€” the convergence ratio Î´ and the initial selection size niâ€”are subsequently inves-tigated. In this study, the input mapping from the discrete GEP-generated models to the continuous values used in the surrogate model is achieved by taking the average values of I1 and I2 along a line at half the channel height in the y-direction shown in Figure 3. Given the large number of possible hyperparameter combinations, con-ducting additional CFD-driven training for each configuration would be com-putationally prohibitive. Therefore, to systematically evaluate the surro-gate framework performance without performing further CFD calculations, a database is constructed from 20 regular CFD-driven training runs with different random seeds. In each run, five different random numbers are pre-defined (as shown in A[1 : 5] in Equation 9), and the resulting datasets are subsequently utilized for passive training. In the passive training pro-cess, the influence of employing a surrogate model and different selection strategiesâ€”namely, the initial selection, selection metric, and threshold set-tingsâ€”is emulated using the existing CFD-driven training data rather than running CFD calculations. Each generation of the emulated training loop consists of three steps. (1) selecting candidate models from the initial model population, (2) adding the corresponding CFD data of the selected models 19 to the training set, and (3) retraining the surrogate model. To identify the optimal surrogate model configuration and selection pro-cess, a total of 59 different combinations of selection metrics and threshold settings, based on the hyperparameters listed in Table 2, were tested. The surrogate modelsâ€™ relative prediction error with respect to the true CFD evaluations, along with the selection ratio (i.e., the proportion of candidate models selected for CFD re-evaluation relative to the total evaluations in the regular CFD-driven training), are plotted in Figure 6. 

> Figure 6: Passive training performance of varying selection metric, threshold and initial selection parameters on the duct flow

Based on the passive training results, the parameter settings achieving the optimal trade-off value in Figure 6 were selected for further validation using surrogate-augmented CFD-driven training: 1. V1: EI, Î¾ = 0 .1, m s,r = 0 .9, n i = 15 

2. V2: EI, Î¾ = 0 .1, m s,r = 0 .05 , m s,f = 1 , n i = 10 , m i,r = 0 .5

3. V3: LCB, Î² = 5 .0, m s,r = 0 .25 , m s,f = 1 , n i = 8 , m i,r = 0 .5

4. V4: EI, Î¾ = 1 .0, m s,r = 0 .1

5. V5: LCB, Î² = 5 .0, m s,r = 0 .25 , m s,p = 1 , n i = 8 , m i,r = 0 .5

6. V6: LCB, Î² = 5 .0, m s,r = 0 .25 , m s,f = 2 

7. V7: LCB, Î² = 3 .0, m s,r = 0 .25 , m s,p = 1 , n i = 10 , m i,r = 0 .5

8. V8: LCB, Î² = 3 .0, m s,r = 0 .25 , m s,p = 1 

9. V9: LCB, Î² = 5 .0, m s,r = 0 .25 , m s,p = 2 

To compare the surrogate model performance for the multi-objective op-timization of the duct flow problem (J(u1), J (u22 + u23)) across the various 20 setups V1â€“V9, two indicators are considered: the number of CFD calcula-tions and a metric called hypervolume coverage, which quantifies how much of the optimal region is occupied by the obtained Pareto front. Hypervolume coverage measures the multi-dimensional volume between the Pareto front and a reference point. Here, the maximum values of each objective on the Pareto front are used as the reference point. A larger hypervolume coverage, therefore, indicates better overall performance. The results for V1â€“V9 are presented in Figure 7 (a). Compared with the baseline CFD-driven training (highlighted in blue), all surrogate-augmented CFD-driven training cases achieve comparable hypervolume coverage with substantially fewer CFD evaluations. A closer examination shows that V1, V3, V6, and V8 achieve larger hypervolume coverage values, approaching unity, than the other configurations. To further improve robustness, a con-vergence weight of Î´ = 0 .5 was introduced in Equation 8 for these four configurations to help the surrogate model exclude non-converged samples, resulting in additional configurations V11, V13, V16, and V18, shown in Figure 7 (b). Among these, V11, V8, and V6 exhibit higher hypervolume coverage, whereas V13 yields a significantly lower CFD cost. Thus, the V6, V8, V11, and V13 setups are recommended hyperparameter combinations. Further selection and validation will be carried out on the VNC case, where both turbulence and heat-flux models are trained simultaneously. (a) (b) 

> Figure 7: Computational costs, i.e. number of CFD evaluations, to achieve hypervolume coverage without (a) and with (b) convergence weight, averaged over 4 validation initial-izations for multi-objective optimization problem of the square duct flow. Opacity of lines represents ratio of training runs reaching the respective fitness level.

Building on the four recommended surrogate hyperparameter setups (V6, 21 V8, V11, and V13) identified from the square duct flow case, we further test these configurations on a more complex optimization problem, where both the turbulence and the heat-flux models are simultaneously improved for the statistically one-dimensional VNC case, to examine whether the recom-mended hyperparameter set can be further refined. For convenience, the four best-performing hyperparameter configurations from the duct-flow case, V6, V8, V11, and V13, are relabeled as V1â€“V4, respectively. In addition, four new configurations (V5â€“V8) are introduced to examine different values of the convergence ratio Î´. The specific setups are as follows: 1. V1: LCB, Î² = 5 , m s,r = 0 .25 , m s,f = 2 

2. V2: LCB, Î² = 3 .0, m s,r = 0 .25 , m s,p = 1 

3. V3: EI, Î¾ = 0 .1, m s,r = 0 .9, n i = 75 , Î´ = 0 .5

4. V4: LCB, Î² = 5 .0, m s,r = 0 .25 , m s,f = 1 , n i = 40 , m i,r = 0 .5, Î´ = 0 .5

5. V5: LCB, Î² = 5 , m s,r = 0 .25 , m s,f = 2 , Î´ = 0 .5

6. V6: LCB, Î² = 3 .0, m s,r = 0 .25 , m s,p = 1 , Î´ = 0 .5

7. V7: EI, Î¾ = 0 .1, m s,r = 0 .9, n i = 75 , Î´ = 0 .1

8. V8: LCB, LCB, Î² = 5 .0, m s,r = 0 .25 , m s,f = 1 , n i = 40 , m i,r = 0 .5, Î´ =0.75 

The input mapping for the surrogate model is obtained using the aver-aged values of I1 and J1 across the distance between the two differentially heated walls shown in Figure 4 (a), based on the baseline RANS results. For the statistically one-dimensional VNC flow, the turbulence-model train-ing produces one coefficient, g1, associated with the first tensor basis V1 

> ij

in Equation 9. Based on previous VNC training experience, the coefficient g4 of the first tensor in the artificial turbulence-production term R (Equation 10) is also included, together with the heat-flux term Î±GEP in Equation 12, re-sulting in three models being trained simultaneously in the multi-objective optimization. After performing the regular CFD-driven training for the VNC turbulence and heat-flux model development, a preliminary test is conducted prior to the surrogate-augmented CFD-driven training to evaluate whether the surrogate model can effectively map the GEP-trained models to the CFD-computed errors. Figure 8 (a) shows all GEP-generated turbulence models, including 

g1 and g4, plotted against the corresponding velocity errors on a logarithmic scale to better illustrate the distribution. Figure 8 (b) presents the GEP-generated turbulence model g1 and the heat flux model Î±GEP plotted against 22 g1

> 0
> 2
> 4
> 6
> 8
> 10
> g4
> 10
> 5
> 0
> 5
> 10
> 15
> 20
> log 10  (U error)
> 3
> 2
> 1
> 0
> 1
> 2
> (a)
> GEP
> 2
> 0
> 2
> 4
> 6
> 8
> g1
> 0
> 1
> 2
> 3
> 4
> log 10  (T error)
> 1
> 0
> 1
> 2
> (b)
> 2
> 1
> 0
> 1
> 2
> U Error
> 1
> 0
> 1
> 2
> T Error

Figure 8: Mapping the regular CFD-driven trained models to predicted errors: (a) velocity error using the GEP-generated turbulence model with an additional turbulence production term; (b) temperature error using the GEP-generated turbulence and heat flux models. 

the corresponding temperature errors, also scaled logarithmically. Both plots exhibit distinct regions of local minima, suggesting that the surrogate model can potentially capture the relationship between the trained models and the observed errors. After gaining confidence in the surrogate modelâ€™s performance on the coupled model predictions shown in Figure 8, we proceeded to apply the hy-perparameter setups V1â€“V8 to the VNC case, as shown in Figure 9. Figure 9 (a) corresponds to the best-performing setups identified from the duct-flow tests, while Figure 9 (b) includes additional configurations obtained by in-troducing a convergence weight of Î´ = 0 .5 for V1 and V2 (yielding V5 and V6), and by decreasing and increasing the convergence weight for V3 and V4, resulting in V7 and V8, respectively. In Figure 9 (a), V4 emerges as the best setup, as it requires fewer CFD simulations compared with V1 and V2, while V3 only reaches a limited hypervolume coverage, with relatively few CFD simulations concentrated in regions of high EI. After assigning or adjusting the convergence ratio Î´, as shown in Figure 9 (b), all configura-tions V5â€“V8 show improved performance compared with V1â€“V4, confirming the importance of the convergence ratio Î´ hyperparameter. Among all cases, V8 demonstrates the best overall performance, achieving a high hypervol-ume coverage with a relatively small number of required CFD simulations. In the remaining two test cases, V8 is therefore adopted as the default hy-perparameter setup for the surrogate model within the surrogate-augmented 23 CFD-driven training framework. (a) (b) 

> Figure 9: Computational costs, i.e. number of CFD evaluations, to achieve hypervolume coverage (a) V1-V4 (b) tuning convergence weight averaged over 4 validation initializations for multi-objective optimization problem of the VNC. Opacity of lines represents ratio of training runs reaching the respective fitness level.

The most straightforward way to evaluate training efficiency is to compare the average prediction error with the number of CFD evaluations required to reach that error level. As shown in Figure 10, the surrogate-based framework achieves the same minimum average error with only 880 CFD evaluations, compared to 2000 required by the regular approach. This results in a training cost reduction of (2000 âˆ’ 880) /2000 = 56% .

3.1.2. Performance of CFD-Driven Trained Models 

The above results focus solely on analyzing the surrogate model hyper-parameter settings and the associated reduction in training cost relative to the standard CFD-driven training framework. This subsection presents the CFD-driven trained models with the smallest errors for the square duct and VNC flows, along with their explicit formulations in Appendix Appendix A. The performance of the CFD-driven trained turbulence model that achieved the minimal error on the square duct is presented in Figure 11, demonstrating the effectiveness of the CFD-driven training approach for turbulence model development. Figure 11 (a) compares the streamwise velocity component, while Figure 11 (b) compares the magnitude of the spanwise and wall-normal velocity components obtained from DNS, the baseline RANS, and the CFD-driven trained model. The contours from the CFD-driven trained model 24 880 2000 Figure 10: Error evolution in regular and surrogate-based CFD-driven training for the VNC case 

capture the secondary flow structures and show better agreement with the DNS results than those from the baseline RANS. The performance of the CFD-driven trained models on the VNC case for the two training objectives, velocity and temperature profiles across the channel height, is presented in Figure 12. Compared to the baseline models (blue solid line), the set of CFD-driven trained models (red dashed line) defined by the explicit expressions in Appendix A exhibits good agreement with the DNS results (black circles). For this statistically one-dimensional mean flow, the governing equations involve only two components of the Reynolds stress tensor and the heat flux vector. With the availability of DNS data, the accuracy of prediction for secondary quantities, such as the turbulence viscosity, Reynolds shear stress, and wall-normal heat flux, can be evaluated, as shown in Figure 13. Based on the Boussinesq assumption, the turbulence viscosity from DNS is obtained using âˆ’uâ€² vâ€² = Î½t dU dy and compared with the turbulence viscosity predicted by the baseline and CFD-driven trained RANS models (Figure 13 a). For the heat flux model evaluation, the wall-normal heat flux is computed us-ing SGDH, âˆ’vâ€² Î¸â€² = Î±t dT dy = Î½t 

> P r t
> dT dy

and compared directly with DNS results (Figure 13 c). The results from the CFD-driven RANS model show much closer agreement with DNS than those of the baseline model, even for sec-ondary quantities not included in the training cost function. This consistent improvement arises because the model training retains rich physical infor-mation within the CFD solver, rather than merely fitting to a limited set of 25 (a) 

DNS Baseline CFD -driven 

(b) Figure 11: Comparison velocity contours between DNS, baseline RANS and CFD-driven trained model: (a) u1; (b) 

q

u22 + u23.0.0 0.2 0.4 0.6 0.8 1.0 

> y/H
> 0.8
> 0.4
> 0.0
> 0.4
> 0.8
> Ux/Uf

(a)      

> 0.0 0.2 0.4 0.6 0.8 1.0
> y/H
> 0.4
> 0.2
> 0.0
> 0.2
> 0.4
> T/ T

(b)   

> DNS Baseline RANS CFD-driven RANS

Figure 12: Performance of the CFD-driven trained models on cost function components: (a) mean velocity and (b) mean temperature profiles across the channel. 

26 target quantities. 0.0 0.1 0.2 0.3 0.4 0.5             

> y/H
> 0.02
> 0.01
> 0.00
> 0.01
> 0.02
> 0.03
> 0.04
> t
> (a)
> 0.0 0.1 0.2 0.3 0.4 0.5
> y/H
> 0.00
> 0.02
> 0.04
> 0.06
> uâ€²vâ€²
> (b)
> 0.0 0.1 0.2 0.3 0.4 0.5
> y/H
> 0.000
> 0.002
> 0.004
> 0.006
> 0.008
> vâ€² â€²
> (c)
> DNS Baseline RANS CFD Driven RANS

Figure 13: Performance of the CFD-driven trained model on non cost function components: (a) turbulence viscosity, (b) the Reynolds shear stress and (c) the wall-normal heat flux. 

The Nusselt number, defined as N u = ( H/ âˆ†T )dT dy |w, characterizes the ratio of convective to conductive heat transfer and is a key parameter of sig-nificant industrial relevance. It is therefore evaluated and compared using both high- and low-fidelity datasets. For this VNC case, the DNS predicts a Nusselt number of 5.37, whereas the baseline RANS model yields 4.33, corresponding to a 19 .4% relative error. In contrast, the CFD-driven trained model predicts 4.86, achieving more than a 50% reduction in error ( 9.5% ), thereby demonstrating improved capability to capture near-wall thermal be-havior. 

3.2. Demonstration cases: horizontal mixed convection and natural convec-tion of concentric horizontal annulus 3.2.1. Evaluation of Surrogate Model Performance 

With the optimal surrogate model configuration determined in the previ-ous section, the surrogate-augmented CFD-driven training framework is now tested on more complex flow cases. The first case considers HMC, where the flow is driven not solely by buoyancy but by the combined effects of buoyancy and an imposed pressure gradient. DNS data for velocity and temperature profiles across a horizontal channel at Ra = 10 8 and three bulk Richardson numbers ( Ri b = 10 , 1, 0.1) are taken from Pirozzoli et al. [32]. The second test case extends the coupled model training to higher-dimensional mean flows, focusing on natural convection in a concentric horizontal annulus at a high Rayleigh number of Ra = 2 .38 Ã—10 10 . The corresponding DNS reference data are taken from [33]. 27 35 5 1900   

> 35 51900
> (a) (b)
> 1257
> 2350 Figure 14: Error evolution in regular and surrogate-augmented CFD-driven training (a) HMC, (b) CHA.

To quantitatively evaluate the training efficiency, Figure 14 presents the evolution of the CFD error for both the regular and surrogate-augmented training approaches. As shown in Figure 14 (a), for the HMC case, the surrogate-based model attains the same level of error reduction after 355 CFD evaluations, whereas the regular framework requires 1900 evaluationsâ€”indicating an 81 .3% improvement in training efficiency. Figure 14 (b) shows the cor-responding results for the CHA case. To achieve a 90% reduction in aver-age error relative to the baseline, the surrogate-based training requires only 1,257 CFD evaluations, compared with 2,350 for the regular framework, cor-responding to a 46 .5% improvement in efficiency. In summary, with the recommended hyperparameter configuration for the surrogate model, the proposed framework achieves a substantial improve-ment in training efficiency across both framework development cases and the two additional demonstration cases, which progressively increase in coupling complexity, flow dimensionality, and Rayleigh number. 

3.2.2. Performance of CFD-Driven Trained Models 

We now examine the performance of the CFD-driven trained model on the two demonstration cases: HMC and CHA. We only train the Ra = 10 8

and Ri = 0 .1 case. Although DNS turbulent quantities are limited to Ra =10 8 in the paper, mean flow quantities, including velocity and temperature, 28 are available for the same Rayleigh number but across varying Richardson numbers. This allows us to assess the generalizability of the GEP-generated model by testing it on cases with the same Ra but different Ri. We begin by examining the performance of the CFD-driven trained HMC model by comparing its mean flow predictions, as shown in Figure 15. Figure 15 shows that the CFD-driven RANS model, trained on a single case, produces mean velocity and temperature predictions that agree better with the DNS data across all Richardson number cases than baseline RANS results. 0.0 0.1 0.2 0.3 0.4 0.5 

> y/H
> 0.0
> 0.2
> 0.4
> 0.6
> 0.8
> 1.0
> U/Ucenter

(a)      

> 0.0 0.1 0.2 0.3 0.4 0.5
> y/H
> 0.0
> 0.1
> 0.2
> 0.3
> 0.4
> 0.5
> (T Tcenter )/  T

(b) 

> DNS Ri=10
> Baseline RANS Ri=10
> CFD-driven RANS Ri=10
> DNS Ri=1
> Baseline RANS Ri=1
> CFD-driven RANS Ri=1
> DNS Ri=0.1
> Baseline RANS Ri=0.1
> CFD-driven RANS Ri=0.1

Figure 15: Comparison of mean flow quantities between DNS, baseline RANS and CFD-driven RANS (a) velocity profile, (b) temperature profile 

Moreover, since the Nusselt number is a key quantity of industrial in-terest and is available from DNS results, it has been calculated using both the baseline and CFD-driven RANS models for all three Richardson-number cases. The corresponding values and errors are summarized in Table 3. The results again show that even when only high-fidelity mean-flow quantities are used during model training, their corresponding gradients can be significantly improved. For the CHA case with Ra = 2 .38 Ã— 10 10 , the two cost function com-ponents, velocity and temperature profiles at 180 â—¦and 120 â—¦, as well as the nonâ€“cost-function profiles at 150 â—¦, are shown in Figures 16. Figures 16 (a)â€“(c) compare the velocity profiles predicted by the DNS, baseline RANS, and CFD-driven trained RANS models, while Figures 16 (d)â€“(f) present the corresponding temperature profiles. In both cases, the coordinate d/r in-29 Table 3: Comparison of Nusselt number between DNS, baseline RANS and CFD-driven RANS Cases DNS Baseline Baseline Error CFD-driven CFD-driven Error RunRa8Ri10 27.672 8.372 69 .746% 27.807 0.48%           

> RunRa8Ri1 25.443 16.744 34 .190% 26.312 3.303%
> RunRa8Ri0.1 45.584 33.787 25 .880% 43.056 5.56%

creases from zero (the hot inner wall) to unity (the cold outer wall). At 180 â—¦,corresponding to the buoyancy-induced jet region, the baseline RANS model exhibits the most considerable discrepancies in both velocity and tempera-ture compared to DNS, whereas the CFD-driven model shows substantial improvement. A closer examination of the entrainment region (Figures 16 (b), (c), (e), and (f)) reveals that the predicted velocity near the cold wall agrees better with DNS than that near the hot wall, with a similar trend observed in the temperature profiles. ð‘¥ 

> ð‘¦
> ð‘§
> 180 Â°
> 150 Â°
> 120 Â°
> ð‘”
> Figure 16: Comparison of mean velocity ((a)-(c)) and temperature profiles ((d)-(e)) be-tween DNS and baseline RANS at three representative angular locations.

To better visualize the mean flow field at various angular positions, velocity-magnitude contours with streamlines are shown in Figure 17 (a), and tem-perature contours with streamlines are shown in Figure 17 (b). The right half of each figure presents the DNS results, while the left half shows the predictions from the baseline RANS and CFD-driven models. In Figure 17 (a), a buoyancy-driven jet can be clearly observed rising from the inner hot wall and impinging on the cold outer wall. The flow then turns laterally 30 due to outer-wall blockage, forming two large vortices characterized by re-duced near-wall velocity and the entrainment of surrounding fluid into the buoyant jet. The CFD-driven model accurately predicts the vortex-center height, consistent with DNS, and significantly improves predictions of the jetâ€™s width and length compared with the baseline model. In Figure 17 (b), the temperature field predicted by the CFD-driven model exhibits a distinct stratification similar to that observed in DNS, with high temperatures con-centrated near the inner hot wall and decreasing gradually toward the outer cold wall. Baseline      

> RANS DNS DNS CFD -driven
> RANS
> (a) (b) Baseline
> RANS DNS DNS CFD -driven
> RANS
> Figure 17: Comparison of mean flow quantities between DNS, baseline RANS, and CFD-driven RANS; (a) velocity magnitude contours with streamline, (b) temperature contours with streamline

Attention is next directed to quantities not directly included as opti-mization targets, TKE and heat-flux distributions, shown in Figure 18. In Figure 18 (a), the baseline RANS model underpredicts TKE and thus pro-vides insufficient turbulent diffusion, producing a narrower jet and weaker temperature rise than DNS, while the CFD-driven model restores the cor-rect spread. Figure 18 (b) shows that the baseline also underestimates the wall heat-flux near the inner hot wall, which is substantially improved by the CFD-driven model, yielding a more accurate thermal response. 

4. Conclusion 

A surrogate-augmented CFD-driven training framework is proposed to substantially reduce the computational cost of model training. Recognizing that the rich information generated during the CFD-driven training pro-cess is underutilized in regular training, the surrogate model leverages these data to establish a mapping between the GEP-generated model parameters and their corresponding cost function values. Instead of evaluating every 31 Baseline       

> RANS DNS DNS CFD -driven
> RANS
> (a) (b) Baseline
> RANS DNS DNS CFD -driven
> RANS Figure 18: Comparison of turbulence quantities between DNS, baseline RANS, and CFD-driven RANS: (a) TKE; (b) heat flux contours.

GEP-generated model through CFD simulations, only those predicted by the surrogate model to have minor errors or large uncertainty ranges are re-evaluated using CFD. The surrogate model itself is also evolved during train-ing. The key components required for developing the surrogate-augmented CFD-driven training approach, including input mapping, surrogate model formulation, and candidate selection criteria for re-evaluation, are described in detail. Various hyperparameter combinations are evaluated on two de-velopment cases: a square-duct flow (turbulence-model training only) and a vertical natural-convection (VNC) flow (joint turbulence- and heat-flux-model training), yielding an optimal surrogate configuration. Using this op-timized setup, the framework is further assessed on two demonstration cases of increasing complexity, namely horizontal mixed convection (HMC) and concentric horizontal annulus (CHA) flows, by training both the turbulence and heat-flux models and comparing the training error evolution against the regular CFD-driven training. It is found that the surrogate-augmented CFD-driven training framework, using a fixed set of hyperparameters, sub-stantially reduces computational cost over the standard CFD-driven training approach while still producing models with significantly improved predictive accuracy. This improvement greatly enhances the practicality and scalability of CFD-driven model development for more complex, industry-relevant flow applications. 

5. Acknowledgment 

The authors from the University of Melbourne acknowledge the financial support and publication permission provided by Mitsubishi Heavy Industries, Ltd. Computational resources were supplied by the Pawsey Supercomputing 32 Centre, funded by the Australian Government and the Government of West-ern Australia under the National Computational Merit Allocation Scheme. 

Appendix A. Explicit expressions of trained models 

The CFD-driven trained turbulence model for the square duct: 

aij = 2 Ïk (âˆ’1.653 + 0 .625 I1 + I2) V 2 

> ij

. (A.1) The CFD-driven trained turbulence and heat-flux model for the VNC: 

aij = 2 Ïk (âˆ’0.098 âˆ’ I1) V 1 

> ij

,bij = 2 Ïk  2 + 0 .847 I1 + I21

 V 1 

> ij

,Î±GEP = 0 .945 âˆ’ 2.108 I1.

(A.2) 

aij and bij are CFD-driven trained components of the turbulence model, where the former is the extra anisotropy stress and the latter is the artificial stress tensor to produce extra turbulence production. For statistically one-dimensional flow, only the first tensor basis is non-zero. Consequently, only the coefficient of V â€² 

> ij

in aij and bij , as well as the one Î±GEP in the heat flux modelâ€”three expressions in totalâ€”need to be trained. For the trained heat flux model Î±GEP = 0 .945 âˆ’ 2.108 I1, which replaces the baseline value 1/P r t,the corresponding trained P r t â‰ˆ 1/0.945 = 1 .0582 . This value lies within the commonly used SGDH range, P r t = 0 .80 âˆ¼ 1.10 ([5]), indicating consistency with established modeling practices. The CFD-driven trained turbulence and heat-flux model for the HMC: 

aij = 2 Ïk (âˆ’0.404 âˆ’ I1) V 1 

> ij

,bij = 2 Ïk  0.43 + I1 âˆ’ 2I21

 V 1 

> ij

,Î±GEP = 2 .0 âˆ’ J1(J1 âˆ’ 2.0) .

(A.3) The CFD-driven trained turbulence and heat-flux model for the CHA: 

aij = 2 Ïk 

h

âˆ’  (N2 âˆ’ N3)( N3 + 0 .089) âˆ’ 0.85  I1 âˆ’ I2(0 .089 N1 + 2 .205) âˆ’ 2N2 + 1 .089 V 1

> ij

+  (I1 âˆ’ 3.0)( N1 + 1 .0) V 2 

> ij

+  N3(4 I2 âˆ’ N1) âˆ’ 0.43 V 3

> ij

i

,Î±GEP = âˆ’0.009409 I1(I1 + J1) + 0 .71 I1 + 1 .3.

(A.4) 33 where N1 = min 

âˆšky  

> 50 Î½

, 2



is the Reynolds number based on the wall dis-tance, N2 = Î½t 

> Î½t+Î½

, is the ratio of turbulent to total (turbulent and molecule) viscosity, and N3 = F2 is the switching function in k âˆ’ Ï‰ SST. 

Declaration of generative AI and AI-assisted technologies in the manuscript preparation process 

During the preparation of this work the author(s) used ChatGPT solely for writing refinement. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the published article. 

References 

[1] Y. Zhao, H. D. Akolekar, J. Weatheritt, V. Michelassi, R. D. Sandberg, RANS turbulence model development using CFD-driven machine learn-ing, Journal of Computational Physics 411 (2020) 109413. [2] I. B. H. SaÃ¯di, M. Schmelzer, P. Cinnella, F. Grasso, CFD-driven sym-bolic identification of algebraic Reynolds-stress models, Journal of Com-putational Physics 457 (2022) 111037. [3] F. Waschkowski, Y. Zhao, R. Sandberg, J. Klewicki, Multi-objective CFD-driven development of coupled turbulence closure models, Journal of Computational Physics 452 (2022) 110922. [4] J. Wu, H. Xiao, R. Sun, Q. Wang, Reynolds-averaged Navierâ€“Stokes equations with explicit data-driven Reynolds stress closure can be ill-conditioned, Journal of Fluid Mechanics 869 (2019) 553â€“586. [5] X. Xu, A. Ooi, R. D. Sandberg, Data-driven algebraic models of the tur-bulent prandtl number for buoyancy-affected flow near a vertical surface, International Journal of Heat and Mass Transfer 179 (2021) 121737. [6] Y. Fang, Y. Zhao, H. D. Akolekar, A. S. Ooi, R. D. Sandberg, R. Pac-ciani, M. Marconcini, A Data-Driven Approach for Generalizing the Laminar Kinetic Energy Model for Separation and Bypass Transi-tion in Low-and High-Pressure Turbines, Vol. 146, 2024, p. 091005. 

doi:10.1115/1.4065124 .34 [7] M. Reissmann, J. Hasslberger, R. D. Sandberg, M. Klein, Application of gene expression programming to a-posteriori LES modeling of a Taylor Green vortex, Journal of Computational Physics 424 (2021) 109859. [8] A. S. Cato, M. Kozul, R. Sandberg, Development of explicit alge-braic les wall models using consistent cfd-driven machine learning, International Journal of Heat and Fluid Flow 117 (2026) 110157. 

doi:https://doi.org/10.1016/j.ijheatfluidflow.2025.110157 .URL https://www.sciencedirect.com/science/article/pii/ S0142727X25004151 

[9] X. Xu, F. Waschkowski, A. S. Ooi, R. D. Sandberg, Towards robust and accurate Reynolds-averaged closures for natural convection via multi-objective CFD-driven machine learning, Int. J. Heat Mass Transf. 187 (2022) 122557. [10] H. Akolekar, F. Waschkowski, R. Sandberg, R. Pacciani, Y. Zhao, Multi-objective development of machine-learnt closures for fully inte-grated transtiion and wake mixing predictions in low pressure turbines, in: Turbo Expo, American Society of Mechanical Engineers, 2022, p. V10CT32A013. [11] Y. Fang, Y. Zhao, F. Waschkowski, A. S. Ooi, R. D. Sandberg, To-ward more general turbulence models via multicase computational-fluid-dynamics-driven training, AIAA Journal 61 (5) (2023) 2100â€“2115. [12] J. Li, X. Du, J. R. Martins, Machine learning in aerodynamic shape optimization, Progress in Aerospace Sciences 134 (2022) 100849. [13] M. Schouler, A. Belme, P. Cinnella, Comparison of multi-fidelity surro-gate models for multi-objective aerodynamic optimization in turboma-chinery under extreme cost imbalance, Advanced Modeling and Simula-tion in Engineering Sciences 12 (1) (2025) 35. [14] F. Fruzza, R. Lamioni, T. Grenga, A. Mariotti, M. V. Salvetti, C. Gal-letti, Mapping flashback velocity in hydrogen-fueled perforated burners over a broad geometric design space, International Journal of Hydrogen Energy 202 (2026) 152980. 35 [15] B. Sudret, S. Marelli, J. Wiart, Surrogate models for uncertainty quan-tification: An overview, in: 2017 11th European conference on antennas and propagation (EUCAP), IEEE, 2017, pp. 793â€“797. [16] R. K. Tripathy, I. Bilionis, Deep uq: Learning deep neural network sur-rogate models for high dimensional uncertainty quantification, Journal of computational physics 375 (2018) 565â€“588. [17] M. J. Asher, B. F. Croke, A. J. Jakeman, L. J. Peeters, A review of surrogate models and their application to groundwater modeling, Water Resources Research 51 (8) (2015) 5957â€“5973. [18] B. Y. Mirghani, E. M. Zechman, R. S. Ranjithan, G. Mahinthakumar, Enhanced simulation-optimization approach using surrogate modeling for solving inverse problems, Environmental Forensics 13 (4) (2012) 348â€“ 363. [19] I. Bilionis, N. Zabaras, B. A. Konomi, G. Lin, Multi-output separable gaussian process: Towards an efficient, fully bayesian paradigm for un-certainty quantification, Journal of Computational Physics 241 (2013) 212â€“239. [20] S. Atkinson, N. Zabaras, Structured bayesian gaussian process latent variable model: Applications to data-driven dimensionality reduction and high-dimensional inversion, Journal of Computational Physics 383 (2019) 166â€“195. [21] Z. Majdisova, V. Skala, Radial basis function approximations: com-parison and applications, Applied Mathematical Modelling 51 (2017) 728â€“743. [22] G. Sun, S. Wang, A review of the artificial neural network surrogate modeling in aerodynamic design, Proceedings of the Institution of Me-chanical Engineers, Part G: Journal of Aerospace Engineering 233 (16) (2019) 5863â€“5872. [23] M. Shi, L. Lv, W. Sun, X. Song, A multi-fidelity surrogate model based on support vector regression, Structural and Multidisciplinary Optimiza-tion 61 (6) (2020) 2363â€“2375. 36 [24] S. K. Dasari, A. Cheddad, P. Andersson, Random forest surrogate mod-els to support design space exploration in aerospace use-case, in: IFIP International Conference on Artificial Intelligence Applications and In-novations, Springer, 2019, pp. 532â€“544. [25] M. C. Kennedy, A. Oâ€™Hagan, Predicting the output from a complex com-puter code when fast approximations are available, Biometrika 87 (1) (2000) 1â€“13. [26] S. Jeong, S. Obayashi, Efficient global optimization (ego) for multi-objective problem and data mining, in: 2005 IEEE congress on evo-lutionary computation, Vol. 3, IEEE, 2005, pp. 2138â€“2145. [27] S. B. Pope, A more general effective-viscosity hypothesis, J. Fluid Mech. 72 (2) (1975) 331â€“340. doi:10.1017/S0022112075003382 .[28] T. B. Gatski, C. G. Speziale, On explicit algebraic stress models for complex turbulent flows, J. Fluid Mech. 254 (1993) 59â€“78. [29] M. Schmelzer, R. P. Dwight, P. Cinnella, Discovery of algebraic reynolds-stress models using sparse symbolic regression, Flow, Turbulence and Combustion 104 (2) (2020) 579â€“603. doi:https://doi.org/10.1007/ s10494-019-00089-x .[30] R. Vinuesa, A. Noorani, A. Lozano-DurÃ¡n, G. K. E. Khoury, P. Schlat-ter, P. F. Fischer, H. M. Nagib, Aspect ratio effects in turbulent duct flows studied through direct numerical simulation, Journal of Turbulence 15 (10) (2014) 677â€“706. [31] C. S. Ng, A. Ooi, D. Lohse, D. Chung, Vertical natural convection: application of the unifying theory of thermal convection, Journal of Fluid Mechanics 764 (2015) 349â€“361. [32] S. Pirozzoli, M. Bernardini, R. Verzicco, P. Orlandi, Mixed convection in turbulent channels with unstable stratification, Journal of fluid me-chanics 821 (2017) 482â€“516. [33] L. Liu, C. Lav, R. Sandberg, A-priori evaluation of data-driven models for large-eddy simulations in natural convection, in: Proceedings of the 22nh Australasian Fluid Mechanics Conference, 2020. 37 [34] J. Ling, J. Templeton, Evaluation of machine learning algorithms for prediction of regions of high reynolds averaged navier stokes uncertainty, Physics of Fluids 27 (8) (2015). 38