# ZENITH: Automated Gradient Norm Informed Stochastic Optimization
# ZENITH：自动化梯度范数告知的随机优化

**Authors**: Dhrubo Saha \
**Date**: 2026-01-21 \
**PDF**: https://arxiv.org/pdf/2601.15212v1 \
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-green">EOH</span> <span class="tag-label tag-green">EAA</span> \
**Score**: 6.0 \
**Evidence**: 学习率的自动演化优化 \
**TLDR**: 引入了ZENITH优化器，利用梯度范数的演化历史自动调整学习率。 \

---

## Abstract
Training deep computer vision models requires manual oversight or hyperparameter tuning of the learning rate (LR) schedule. While existing adaptive optimizers schedule the LR automatically, they suffer from computational and memory overhead, incompatibility with regularization, and suboptimal LR choices. In this work, we introduce the ZENITH (Zero-overhead Evolution using Norm-Informed Training History) optimizer, which adapts the LR using the temporal evolution of the gradient norm. Image classification experiments spanning 6 CNN architectures and 6 benchmarks demonstrate that ZENITH achieves higher test accuracy in lower wall-clock time than baselines. It also yielded superior mAP in object detection, keypoint detection, and instance segmentation on MS COCO using the R-CNN family of models. Furthermore, its compatibility with regularization enables even better generalization.

## 摘要
训练深度计算机视觉模型需要对学习率（LR）调度进行

---

## 速览摘要（自动生成）

**问题**：深度学习模型训练依赖繁琐的学习率调优，且现有自适应
