# An Empirical Study on Ensemble-Based Transfer Learning Bayesian Optimisation with Mixed Variable Types
# 混合变量类型下基于集成的迁移学习贝叶斯优化的实证研究

**Authors**: Natasha Trinkle, Huong Ha, Jeffrey Chan \
**Date**: 2026-01-22 \
**PDF**: https://arxiv.org/pdf/2601.15640v1 \
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-green">EAA</span> \
**Score**: 6.0 \
**Evidence**: 高效自动算法选择与优化迁移学习 \
**TLDR**: 分析贝叶斯优化的集成迁移学习方法，以提高样本效率。

---

## 速览
**TLDR**：本研究对混合变量类型的集成迁移学习贝叶斯优化进行了实证分析，并提出了改进组件和新基准。
**Motivation**：旨在利用历史数据提升昂贵黑盒函数优化的效率，并解决迁移学习可能失效的问题。
**Method**：提出了一种基于正值约束正则化回归的集成代理模型加权策略，并引入了热启动初始化和负迁移处理机制。
**Result**：实验表明，热启动初始化和对集成模型权重施加正值约束能显著提升迁移学习贝叶斯优化的性能。
**Conclusion**：优化贝叶斯优化流水线中的特定组件（如权重约束和初始化方式）是实现高效迁移学习的关键。

---

## Abstract
Bayesian optimisation is a sample efficient method for finding a global optimum of expensive black-box objective functions. Historic datasets from related problems can be exploited to help improve performance of Bayesian optimisation by adapting transfer learning methods to various components of the Bayesian optimisation pipeline. In this study we perform an empirical analysis of various ensemble-based transfer learning Bayesian optimisation methods and pipeline components. We expand on previous work in the literature by contributing some specific pipeline components, and three new real-time transfer learning Bayesian optimisation benchmarks. In particular we propose to use a weighting strategy for ensemble surrogate model predictions based on regularised regression with weights constrained to be positive, and a related component for handling the case when transfer learning is not improving Bayesian optimisation performance. We find that in general, two components that help improve transfer learning Bayesian optimisation performance are warm start initialisation and constraining weights used with ensemble surrogate model to be positive.

## 摘要
贝叶斯优化是一种用于寻找高代价黑盒目标函数全局最优解的样本高效方法。通过将迁移学习方法应用于贝叶斯优化流水线的各个组件，可以利用来自相关问题的历史数据集来提高贝叶斯优化的性能。在本研究中，我们对各种基于集成的迁移学习贝叶斯优化方法及其流水线组件进行了实证分析。我们通过贡献特定的流水线组件以及三个新的实时迁移学习贝叶斯优化基准，扩展了文献中的先前工作。特别地，我们提出了一种基于正则化回归的集成代理模型预测加权策略，其中权重被约束为正值，并提出了一个相关组件用于处理迁移学习未能提升贝叶斯优化性能的情况。我们发现，通常情况下，有助于提高迁移学习贝叶斯优化性能的两个组件是热启动初始化以及将集成代理模型所使用的权重约束为正值。