# Martingale Foresight Sampling: A Principled Approach to Inference-Time LLM Decoding
# 鞅前瞻采样：一种基于原则的推理阶段大语言模型解码方法

**Authors**: Huayu Li, ZhengXiao He, Siyuan Tian, Jinghao Wen, Ao Li \
**Date**: 2026-01-21 \
**PDF**: https://arxiv.org/pdf/2601.15482v1 \
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-green">LNS</span> <span class="tag-label tag-green">EAA</span> \
**Score**: 6.0 \
**Evidence**: LLM 解码中原则性的搜索空间剪枝和路径评估 \
**TLDR**: 提出鞅前瞻采样，为 LLM 解码提供有理论依据的最优搜索。

---

## 速览
**TLDR**：提出一种基于鞅理论（Martingale theory）的推理时解码框架 MFS，通过概率论原理优化 LLM 的路径搜索与剪枝。
**Motivation**：传统的自回归解码过于短视，且现有的前瞻采样方法多依赖启发式规则，缺乏严谨的理论支撑。
**Method**：将解码建模为随机过程，利用 Doob 分解进行路径估值，结合可选停止定理进行剪枝，并依据鞅收敛定理实现自适应停止。
**Result**：在六个推理基准测试中，MFS 在准确率上超越了现有最先进方法，并显著提升了计算效率。
**Conclusion**：MFS 为 LLM 推理提供了一个理论完备且高效的解码框架，证明了概率论在优化复杂推理路径中的有效性。

---

## Abstract
Standard autoregressive decoding in large language models (LLMs) is inherently short-sighted, often failing to find globally optimal reasoning paths due to its token-by-token generation process. While inference-time strategies like foresight sampling attempt to mitigate this by simulating future steps, they typically rely on ad-hoc heuristics for valuing paths and pruning the search space. This paper introduces Martingale Foresight Sampling (MFS), a principled framework that reformulates LLM decoding as a problem of identifying an optimal stochastic process. By modeling the quality of a reasoning path as a stochastic process, we leverage Martingale theory to design a theoretically-grounded algorithm. Our approach replaces heuristic mechanisms with principles from probability theory: step valuation is derived from the Doob Decomposition Theorem to measure a path's predictable advantage, path selection uses Optional Stopping Theory for principled pruning of suboptimal candidates, and an adaptive stopping rule based on the Martingale Convergence Theorem terminates exploration once a path's quality has provably converged. Experiments on six reasoning benchmarks demonstrate that MFS surpasses state-of-the-art methods in accuracy while significantly improving computational efficiency. Code will be released at https://github.com/miraclehetech/EACL2026-Martingale-Foresight-Sampling.

## 摘要
大语言模型（LLM）中的标准自回归解码本质上是短视的，由于其逐 token 生成的过程，往往无法找到全局最优的推理路径。虽然前瞻采样（foresight sampling）等推理阶段策略试图通过模拟未来步骤来缓解这一问题，但它们通常依赖于特定的启发式方法来评估路径和剪枝搜索空间。本文介绍了鞅前瞻采样（Martingale Foresight Sampling, MFS），这是一个基于原则的框架，将 LLM 解码重新表述为识别最优随机过程的问题。通过将推理路径的质量建模为随机过程，我们利用鞅理论（Martingale theory）设计了一种具有理论依据的算法。我们的方法用概率论原则取代了启发式机制：步骤评估源自 Doob 分解定理（Doob Decomposition Theorem），用于衡量路径的可预测优势；路径选择利用选择性停时理论（Optional Stopping Theory）对次优候选路径进行有原则的剪枝；基于鞅收敛定理（Martingale Convergence Theorem）的自适应停止规则则在路径质量被证明收敛后终止探索。在六个推理基准测试上的实验表明，MFS 在准确率上超越了现有最先进的方法，同时显著提高了计算效率。代码将发布于 https://github.com/miraclehetech/EACL2026-Martingale-Foresight-Sampling。