---
title: "Introns and Templates Matter: Rethinking Linkage in GP-GOMEA"
title_zh: 内含子与模板的重要性：重新思考 GP-GOMEA 中的连锁
authors: "Johannes Koch, Tanja Alderliesten, Peter A. N. Bosman"
date: 2026-02-02
pdf: "https://arxiv.org/pdf/2602.02311v1"
tags: ["keyword:SR", "query:SR"]
score: 10.0
evidence: 直接改进了 GP-GOMEA（一种最先进的符号回归算法），解决了连锁和内含子问题。
tldr: GP-GOMEA是符号回归领域的先进算法，其核心在于利用节点间的联动性（Linkage）来优化进化过程。然而，现有方法在固定模板下产生的内含子（Introns）会干扰联动性的准确学习。本文重新审视了这一机制，提出了两种改进方案：一种在互信息估计中显式考虑内含子，另一种则直接从模板结构推导联动性。实验表明，新方法显著提升了算法性能，且直接利用模板结构的联动性表现最优。
motivation: 现有的GP-GOMEA联动性学习受内含子干扰，导致互信息无法准确捕捉树节点间的真实依赖关系。
method: 提出了考虑内含子的互信息度量方法，以及一种直接基于表达式模板结构的灰盒联动性度量方案。
result: 在五个标准符号回归问题上，新方法均取得了显著的性能提升，且发现学习到的联动结构与模板结构高度一致。
conclusion: 显式处理内含子或直接利用模板结构能更有效地引导进化，是优化GP-GOMEA联动性学习的关键方向。
---

## 摘要
GP-GOMEA 是符号回归领域的先进方法之一，尤其擅长寻找小型且具有潜在可解释性的解。任何 GOMEA 变体中采用的关键机制都是利用连锁（即变量之间的依赖关系），以确保高效的进化。在 GP-GOMEA 中，迄今为止一直使用 GP 树中节点位置之间的互信息来学习连锁。为此，需要使用一个固定的表达式模板。然而，对于小于完整模板的表达式，这会导致内含子的产生。由于内含子对适应度没有影响，它们的出现与选择过程没有直接联系。因此，内含子可能会对互信息捕捉树节点之间依赖关系的准确性产生不利影响。为了克服这一问题，我们提出了两种新的连锁学习度量方法：一种在互信息估计中明确考虑了内含子；另一种从灰盒视角重新审视 GP-GOMEA 中的连锁学习，从而得到一种无需从种群中学习、而是直接从模板中推导出的度量。在五个标准符号回归问题上，使用这两种度量的 GP-GOMEA 都取得了显著的改进。我们还发现，新学习到的连锁结构紧密反映了模板连锁结构，并且明确使用模板结构在整体上表现最佳。

## Abstract
GP-GOMEA is among the state-of-the-art for symbolic regression, especially when it comes to finding small and potentially interpretable solutions. A key mechanism employed in any GOMEA variant is the exploitation of linkage, the dependencies between variables, to ensure efficient evolution. In GP-GOMEA, mutual information between node positions in GP trees has so far been used to learn linkage. For this, a fixed expression template is used. This however leads to introns for expressions smaller than the full template. As introns have no impact on fitness, their occurrences are not directly linked to selection. Consequently, introns can adversely affect the extent to which mutual information captures dependencies between tree nodes. To overcome this, we propose two new measures for linkage learning, one that explicitly considers introns in mutual information estimates, and one that revisits linkage learning in GP-GOMEA from a grey-box perspective, yielding a measure that needs not to be learned from the population but is derived directly from the template. Across five standard symbolic regression problems, GP-GOMEA achieves substantial improvements using both measures. We also find that the newly learned linkage structure closely reflects the template linkage structure, and that explicitly using the template structure yields the best performance overall.

---

## 论文详细总结（自动生成）

这篇论文对符号回归（SR）领域的先进算法 GP-GOMEA 进行了深入的重新审视，重点探讨了如何通过改进“连锁学习（Linkage Learning）”机制来提升算法性能。

以下是对该论文的结构化总结：

### 1. 核心问题与研究动机
*   **核心问题**：在 GP-GOMEA 算法中，为了保持种群结构一致，通常使用固定的表达式模板（如满二叉树）。这导致许多节点成为“内含子（Introns）”（即对最终数学表达式无贡献的无效节点）。
*   **研究动机**：现有的连锁学习方法（如互信息 MI）在计算节点间的依赖关系时，未区分活跃节点和内含子。由于内含子不受选择压力影响，其数值分布接近随机噪声，严重干扰了互信息的估计，导致算法无法准确捕捉变量间的真实耦合关系，从而限制了进化效率。

### 2. 方法论
论文提出了两种改进连锁学习的新度量方法：

*   **掩码互信息（Masked MI）**：
    *   **核心思想**：在计算熵和互信息时，显式识别每个解中的内含子。
    *   **技术细节**：将所有处于内含子状态的节点标记为一个特殊的“掩码（Masked）”标签。这样，互信息的计算将完全基于活跃节点的语义贡献，消除了无效节点产生的统计噪声。
*   **节点邻近度（Node Proximity，灰盒视角）**：
    *   **核心思想**：放弃从种群统计数据中学习连锁，转而直接利用表达式模板的拓扑结构。
    *   **技术细节**：基于树模板中节点间的距离定义相似度。距离越近的节点（如父子关系、兄弟关系）相似度越高。公式通过归一化节点间的路径长度来构建相似度矩阵。这种方法属于“灰盒”优化，因为它利用了算法已知的结构信息。

### 3. 实验设计
*   **数据集**：使用了 5 个标准的符号回归基准问题：Airfoil（机翼噪声）、Bike Sharing（共享单车）、Concrete（混凝土强度）、Dow Chemical（陶氏化学）和 Tower（塔式结构）。
*   **对比方法（Baselines）**：
    *   **Random**：随机连锁。
    *   **MI**：标准的互信息度量。
    *   **MI Adjusted**：之前最先进的偏置修正互信息度量。
    *   **Univariate**：假设变量间完全独立的单变量模型（补充材料中提到）。
*   **实验变量**：测试了不同的模板高度（5 层和 7 层）以及是否启用线性缩放（Linear Scaling, LS）。

### 4. 资源与算力
*   **硬件环境**：实验在配备两颗 **Intel Xeon E5-2699v4** 处理器的机器上运行，每个实验任务运行在独立的物理核心上以确保时间可比性。
*   **计算预算**：每个运行任务的计算预算设定为 **$10^7$ 次适应度评估**。
*   **训练时长**：根据数据集规模不同，运行时间从几分钟到数小时不等（例如 Tower 数据集耗时较长）。

### 5. 实验数量与充分性
*   **实验规模**：每个配置组合（算法 x 数据集 x 模板高度 x LS）均进行了 **30 次独立重复实验**，并采用了 5 折交叉验证。
*   **充分性与公平性**：
    *   使用了相同的随机种子初始化种群，确保起点公平。
    *   采用了统计学界推荐的 **R2 分数** 作为评价指标。
    *   使用了 **Friedman 检验** 和 **Nemenyi 后验检验** 以及自助法（Bootstrap）置信区间进行显著性分析。
    *   实验覆盖了不同特征维度（5 到 57 个特征）和样本量的数据集，实验设计非常充分且客观。

### 6. 主要结论与发现
*   **性能提升**：提出的 **Node Proximity（节点邻近度）** 表现最优，其次是 **Masked MI**。两者在准确率和收敛速度上均显著优于现有的 MI 方法。
*   **效率优势**：使用新度量方法的 GP-GOMEA 在仅消耗一半计算预算的情况下，就能达到甚至超过传统方法最终的准确度。
*   **连锁结构的本质**：研究发现，通过种群学习到的连锁结构最终都会趋向于反映模板的物理结构。这意味着直接使用模板结构（Node Proximity）不仅效果好，还节省了每代计算互信息的开销。
*   **内含子的影响**：证实了内含子确实是连锁学习中的主要噪声源，处理内含子是提升 GP 性能的关键。

### 7. 优点
*   **见解深刻**：揭示了 GP-GOMEA 中连锁学习的本质其实是对树结构的回归。
*   **简单高效**：Node Proximity 方法不需要运行时的统计计算，极大地降低了算法的计算负担。
*   **通用性**：掩码处理内含子的思想可以推广到其他具有条件活跃变量的进化算法中。

### 8. 不足与局限
*   **模板依赖**：Node Proximity 极度依赖于预定义的模板结构。如果问题的真实结构与树模板差异巨大，该方法的优势可能会减弱。
*   **数据集覆盖**：虽然涵盖了 5 个典型问题，但对于极高维度或具有极端非线性特征的复杂科学发现问题，其表现尚待进一步验证。
*   **可解释性权衡**：虽然算法倾向于寻找小表达式，但论文未深入探讨新连锁机制对最终表达式“人类可读性”的具体影响。

（完）
