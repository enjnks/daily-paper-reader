---
title: In-Context System Identification for Nonlinear Dynamics Using Large Language Models
title_zh: 使用大语言模型的非线性动力学上下文系统辨识
authors: Linyu Lin
date: 2026-02-07
pdf: "https://arxiv.org/pdf/2602.07360v1"
tags: ["keyword:SR", "query:SR"]
score: 9.0
evidence: LLM辅助发现简约控制方程
tldr: 针对非线性动力系统识别中 SINDy 方法依赖专家调优的问题，本文提出一种利用大语言模型（LLM）进行上下文学习的迭代优化框架。该方法将 LLM 引入 SINDy 循环，通过分析误差指标和领域约束来启发式地改进候选方程结构。在 63 个动力系统数据集上的实验表明，该方法在符号恢复准确性和预测精度上均优于传统 SINDy，实现了数据驱动误差反馈与符号推理的有效结合。
motivation: 传统的 SINDy 方法在发现控制方程时高度依赖候选库的专家设计，难以处理复杂的非线性动力学。
method: 提出一种 LLM 辅助的 SINDy 流水线，通过将当前最佳方程和误差指标输入 LLM，利用上下文学习迭代优化方程结构。
result: 在 ODEBench 等 63 个数据集上的测试显示，该方法在结构相似度和测试均方根误差（RMSE）方面均显著优于基准 SINDy。
conclusion: LLM 能够有效引导 SINDy 在方程空间中的搜索，通过整合数据反馈与符号推理，发现更准确且具可解释性的控制方程。
---

## 摘要
非线性动力学稀疏识别（SINDy）是从数据中发现简洁控制方程的一种强大方法，但它通常需要专家对候选库进行调优。我们提出了一种 LLM 辅助的 SINDy 流水线，通过上下文学习（in-context learning），在循环中使用大语言模型（LLM）迭代优化候选方程。该流水线首先使用自适应库拟合基准 SINDy 模型，然后进入 LLM 引导的优化循环。在每次迭代中，当前的最佳方程、误差指标和特定领域约束被汇总到 LLM 的提示词中，由其建议新的方程结构。这些候选方程根据定义的符号形式进行解析，并在训练和测试数据上进行评估。该流水线将基于模拟的误差作为主要指标，同时也评估与真实值（ground truth）的结构相似性，包括匹配函数形式、关键项、耦合和定性行为。如果测试误差低于阈值（NRMSE < 0.1）或达到最大 10 次迭代，迭代停止标准将提前结束优化。最后，选择最佳模型，我们在 63 个动力系统数据集（ODEBench）和用于沸水核反应堆的 March-Leuba 模型上评估了这种 LLM 辅助的 SINDy。结果与经典 SINDy 进行了对比，表明在复杂动力学情况下，LLM 循环一致地提高了符号恢复能力，与基准 SINDy 相比，具有更高的方程结构相似性和更低的测试 RMSE。这项工作证明了 LLM 可以有效地引导 SINDy 在方程空间中的搜索，将数据驱动的误差反馈与受领域启发的符号推理相结合，从而发现不仅准确而且在结构上具有可解释性的控制方程。

## Abstract
Sparse Identification of Nonlinear Dynamics (SINDy) is a powerful method for discovering parsimonious governing equations from data, but it often requires expert tuning of candidate libraries. We propose an LLM-aided SINDy pipeline that iteratively refines candidate equations using a large language model (LLM) in the loop through in-context learning. The pipeline begins with a baseline SINDy model fit using an adaptive library and then enters a LLM-guided refinement cycle. At each iteration, the current best equations, error metrics, and domain-specific constraints are summarized in a prompt to the LLM, which suggests new equation structures. These candidate equations are parsed against a defined symbolic form and evaluated on training and test data. The pipeline uses simulation-based error as a primary metric, but also assesses structural similarity to ground truth, including matching functional forms, key terms, couplings, qualitative behavior. An iterative stopping criterion ends refinement early if test error falls below a threshold (NRMSE < 0.1) or if a maximum of 10 iterations is reached. Finally, the best model is selected, and we evaluate this LLM-aided SINDy on 63 dynamical system datasets (ODEBench) and march leuba model for boiling nuclear reactor. The results are compared against classical SINDy and show the LLM-loop consistently improves symbolic recovery with higher equation similarity to ground truth and lower test RMSE than baseline SINDy for cases with complex dynamics. This work demonstrates that an LLM can effectively guide SINDy's search through equation space, integrating data-driven error feedback with domain-inspired symbolic reasoning to discover governing equations that are not only accurate but also structurally interpretable.

---

## 论文详细总结（自动生成）

这篇论文提出了一种结合大语言模型（LLM）与稀疏识别算法（SINDy）的新型框架，旨在自动化非线性动力系统的控制方程发现过程。以下是对该论文的深度结构化总结：

### 1. 核心问题与整体含义（研究动机和背景）
*   **核心问题**：传统的 **SINDy** 算法高度依赖于人工预设的“候选函数库”。如果真实的物理项不在库中，算法将无法识别出正确的方程。此外，专家调优过程耗时且需要深厚的领域知识。
*   **研究背景**：在数据驱动的科学发现中，如何从时间序列数据中提取既准确又具有可解释性的符号方程是核心挑战。虽然深度学习（如 Neural ODEs）能拟合轨迹，但往往是“黑盒”；而符号回归虽能给出公式，但在搜索空间巨大时效率低下。
*   **整体含义**：本文试图利用 LLM 的符号推理能力和广泛的科学知识储备，将其作为“假设生成器”引入 SINDy 的迭代循环中，实现自适应的函数库扩展和方程优化。

### 2. 方法论：核心思想与技术细节
该方法被称为 **LLM-aided SINDy**，其核心是一个闭环迭代流水线：
*   **初始化与基准拟合**：首先使用标准的 SINDy 和一个宽泛的固定库进行初步拟合，提取状态变量的特征（如量程、是否振荡、是否饱和等）。
*   **LLM 引导的优化循环**：
    1.  **Prompt 构造**：将当前最佳方程、训练/测试误差指标、数据定性特征（如“振荡”）、领域约束（如变量物理含义）以及之前失败的尝试汇总成 Prompt 发送给 LLM。
    2.  **候选结构生成**：LLM 根据上下文建议新的函数形式（如指数项、双线性耦合项等），要求必须满足线性参数化形式：$\dot{x}_i(t) = \sum \theta_{i,k} \phi_k(x, u, t)$。
    3.  **解析与验证**：系统自动解析 LLM 输出的符号表达式，剔除不符合语法或违反线性参数约束的项。
    4.  **稀疏回归与模拟评估**：使用稀疏回归估计系数，并通过前向模拟（Forward Simulation）计算测试集上的 NRMSE（归一化均方根误差）。
*   **多目标评分与停止准则**：
    *   使用公式 $J = \max NRMSE_i + \lambda_c \mathcal{C} + \lambda_p \mathcal{P}$ 进行评分，平衡预测精度、符号复杂度（$\mathcal{C}$）和领域先验惩罚（$\mathcal{P}$）。
    *   当 $NRMSE < 0.1$ 或达到 10 次迭代上限时停止。

### 3. 实验设计
*   **数据集**：
    *   **ODEBench**：包含 63 个不同的常微分方程（ODE）系统，涵盖 1D 到 4D 动力学，包括捕食者-猎物模型、振荡器、反应动力学及 4 个混沌系统。
    *   **March-Leuba 模型**：一个复杂的 7 变量沸水核反应堆（BWR）稳定性模型，具有强耦合和非线性反馈。
*   **Benchmark（基准）**：经典 SINDy（使用固定且全面的多项式及三角函数库）。
*   **对比指标**：预测精度（$R^2$、NRMSE）和符号恢复质量（是否找回了真实的物理项）。

### 4. 资源与算力
*   **算力说明**：论文中**未明确提及**具体的 GPU 型号、数量或具体的训练/推理时长。
*   **实现细节**：由于核心是调用 LLM（通过 API 或本地部署）进行文本生成，主要的计算开销在于：(1) LLM 的推理；(2) 迭代过程中多次进行 ODE 数值积分模拟。

### 5. 实验数量与充分性
*   **实验规模**：在 63 个标准 benchmark 任务上进行了全面测试，并增加了一个复杂的核工程实际案例。
*   **充分性**：实验涵盖了从简单线性到复杂混沌、从低维到高维的多种场景，样本量足以证明方法的通用性。
*   **客观性**：通过与固定库的基准 SINDy 进行直接对比，并使用公开的 ODEBench 数据集，实验设计较为客观、公平。

### 6. 主要结论与发现
*   **精度提升**：在 63 个系统中，LLM 辅助方法在 48 个系统上达到了停止准则（NRMSE < 0.1），而基准 SINDy 仅为 30 个。
*   **误差降低**：LLM 辅助方法的测试误差中位数为 3.4%，远低于基准 SINDy 的 62%。
*   **结构恢复**：LLM 能够有效识别出基准库中缺失的项（如指数项 $e^{-x}$ 或复杂的双线性耦合项 $x^2y$），显著提高了物理规律的发现率（36/63 vs 26/63）。
*   **稳定性**：在基准 SINDy 出现数值发散（Infinite Error）的 5 个案例中，LLM 辅助流水线均成功找到了稳定的模型。

### 7. 优点（亮点）
*   **自适应性**：突破了 SINDy 对固定候选库的依赖，使算法能够“跳出盒子”思考。
*   **专家模拟**：成功模拟了人类专家“观察误差 -> 提出假设 -> 验证修改”的迭代建模过程。
*   **可解释性**：保留了 SINDy 的符号化优点，生成的模型对物理学家来说是透明且可验证的。
*   **鲁棒性**：引入了模拟反馈机制，确保选出的模型不仅拟合导数好，且在长程预测中保持稳定。

### 8. 不足与局限
*   **LLM 依赖性**：系统的上限取决于 LLM 的推理能力。如果 LLM 无法提出正确的函数形式，搜索仍会失败。
*   **计算成本**：相比一键式的 SINDy，迭代循环（尤其是多次 ODE 模拟）会显著增加计算时间。
*   **复杂项组合爆炸**：虽然 LLM 能建议新项，但对于极其复杂的复合函数（如 $\cot(y) \cos(x)$），目前的线性参数化框架仍难以完美处理。
*   **随机性风险**：LLM 的输出具有随机性，可能导致在不同运行中发现的方程不一致，需要更强的验证机制。

（完）
