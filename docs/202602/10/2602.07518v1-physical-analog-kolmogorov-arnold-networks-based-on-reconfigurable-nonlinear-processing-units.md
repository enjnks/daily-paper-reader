---
title: Physical Analog Kolmogorov-Arnold Networks based on Reconfigurable Nonlinear-Processing Units
title_zh: 基于可重构非线性处理单元的物理模拟 Kolmogorov-Arnold 网络
authors: "Manuel Escudero, Mohamadreza Zolfagharinejad, Sjoerd van den Belt, Nikolaos Alachiotis, Wilfred G. van der Wiel"
date: 2026-02-07
pdf: "https://arxiv.org/pdf/2602.07518v1"
tags: ["keyword:SR", "query:SR"]
score: 6.0
evidence: KAN网络作为符号回归的替代方案
tldr: 本研究提出了一种基于可重构非线性处理单元（RNPU）的物理模拟 Kolmogorov-Arnold 网络（aKAN）架构。通过利用多端纳米级硅器件的非线性特性，实现了硬件原生的可学习边缘函数。该架构在保持高精度的同时，相比传统数字多层感知器（MLP），在能效上提升了两个数量级，面积缩小了十倍，为边缘计算提供了高效的硬件方案。
motivation: 旨在解决 Kolmogorov-Arnold 网络（KAN）中复杂的非线性边缘函数在传统硬件上难以高效实现的问题。
method: 提出一种模拟 KAN 架构，利用可重构非线性处理单元（RNPU）作为核心，通过控制电压调节纳米硅器件的输入输出特性来实现可编程非线性变换。
result: 实验证明 aKAN 在回归和分类任务中表现优异，且相比数字 MLP，其推理能耗降低了 100-1000 倍，芯片面积缩小了约 10 倍。
conclusion: 该研究证明了 RNPU 是可扩展的硬件原生非线性计算原语，为开发低功耗、低延迟和高集成度的模拟神经网络硬件开辟了新路径。
---

## 摘要
Kolmogorov-Arnold 网络 (KANs) 将神经计算从线性层转向可学习的非线性边函数，但在硬件中高效实现这些非线性仍是一个开放性挑战。在此，我们介绍了一种物理模拟 KAN 架构，其中边函数是利用可重构非线性处理单元 (RNPUs) 在材料中实现的：这是一种多端纳米级硅器件，其输入输出特性可通过控制电压进行调节。通过将多个 RNPU 组合成边处理器，并将这些模块组装成具有集成混合信号接口的可重构模拟 KAN (aKAN) 架构，我们建立了一个现实的系统级硬件实现，能够通过可编程非线性变换实现紧凑的 KAN 式回归和分类。利用经过实验校准的 RNPU 模型和硬件测量，我们证明了在任务复杂度增加的情况下，该架构能够实现准确的函数逼近，且所需的训练参数少于或等同于多层感知器 (MLPs)。系统级评估表明，对于代表性工作负载，其每次推理能耗约为 250 pJ，端到端推理延迟约为 600 ns；与具有相似逼近误差的数字定点 MLP 相比，能耗降低了约 10²-10³ 倍，面积减少了约 10 倍。这些结果确立了 RNPU 作为可扩展、硬件原生的非线性计算原语的地位，并表明模拟 KAN 架构是实现高能效、低延迟、小尺寸模拟神经网络硬件（特别是针对边缘推理）的一条现实的硅基路径。

## Abstract
Kolmogorov-Arnold Networks (KANs) shift neural computation from linear layers to learnable nonlinear edge functions, but implementing these nonlinearities efficiently in hardware remains an open challenge. Here we introduce a physical analog KAN architecture in which edge functions are realized in materia using reconfigurable nonlinear-processing units (RNPUs): multi-terminal nanoscale silicon devices whose input-output characteristics are tuned via control voltages. By combining multiple RNPUs into an edge processor and assembling these blocks into a reconfigurable analog KAN (aKAN) architecture with integrated mixed-signal interfacing, we establish a realistic system-level hardware implementation that enables compact KAN-style regression and classification with programmable nonlinear transformations. Using experimentally calibrated RNPU models and hardware measurements, we demonstrate accurate function approximation across increasing task complexity while requiring fewer or comparable trainable parameters than multilayer perceptrons (MLPs). System-level estimates indicate an energy per inference of $\sim$250 pJ and an end-to-end inference latency of $\sim$600 ns for a representative workload, corresponding to a $\sim$10$^{2}$-10$^{3}\times$ reduction in energy accompanied by a $\sim$10$\times$ reduction in area compared to a digital fixed-point MLP at similar approximation error. These results establish RNPUs as scalable, hardware-native nonlinear computing primitives and identify analog KAN architectures as a realistic silicon-based pathway toward energy-, latency-, and footprint-efficient analog neural-network hardware, particularly for edge inference.