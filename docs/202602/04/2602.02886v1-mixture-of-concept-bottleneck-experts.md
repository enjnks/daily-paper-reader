---
title: Mixture of Concept Bottleneck Experts
title_zh: 概念瓶颈专家混合
authors: "Francesco De Santis, Gabriele Ciravegna, Giovanni De Felice, Arianna Casanova, Francesco Giannini, Michelangelo Diligenti, Mateo Espinosa Zarlenga, Pietro Barbiero, Johannes Schneider, Danilo Giordano"
date: 2026-02-02
pdf: "https://arxiv.org/pdf/2602.02886v1"
tags: ["keyword:SR", "query:SR"]
score: 10.0
evidence: 利用符号回归发现专家函数
tldr: 本研究针对概念瓶颈模型（CBM）预测器形式单一、准确性与适应性受限的问题，提出了概念瓶颈专家混合（M-CBE）框架。该框架通过增加专家数量并引入多样化的函数形式（如线性专家和基于符号回归的专家），扩展了 CBM 的设计空间。实验证明，M-CBE 能在保持可解释性的同时，通过灵活调整专家配置，有效优化预测性能并满足不同用户的需求。
motivation: 传统 CBM 仅使用单一的线性或布尔表达式作为预测器，限制了模型的预测精度和对复杂任务的适应能力。
method: 提出 M-CBE 框架，通过引入多个专家模型及符号回归等多样化函数形式，增强了概念到预测的映射能力。
result: 实验结果显示，改变专家混合规模和函数形式可以显著提升模型在准确性与可解释性权衡中的表现。
conclusion: M-CBE 框架为构建兼具高性能和高可解释性的深度学习模型提供了一种灵活且有效的通用方案。
---

## 摘要
概念瓶颈模型 (CBMs) 通过将预测建立在人类可理解的概念之上来提升可解释性。然而，现有的 CBMs 通常将其任务预测器固定为单一的线性或布尔表达式，这限制了预测准确性以及对多样化用户需求的适应性。我们提出了概念瓶颈专家混合 (M-CBEs)，这是一个在两个维度上对现有 CBMs 进行泛化的框架：专家数量和每个专家的函数形式，从而揭示了设计空间中一个尚未被充分探索的领域。我们通过实例化两个新模型来研究这一领域：线性 M-CBE（学习有限的线性表达式集合）和符号 M-CBE（利用符号回归在用户指定的算子词汇表下从数据中发现专家函数）。实证评估表明，改变混合规模和函数形式为权衡准确性与可解释性提供了一个稳健的框架，能够适应不同的用户和任务需求。

## Abstract
Concept Bottleneck Models (CBMs) promote interpretability by grounding predictions in human-understandable concepts. However, existing CBMs typically fix their task predictor to a single linear or Boolean expression, limiting both predictive accuracy and adaptability to diverse user needs. We propose Mixture of Concept Bottleneck Experts (M-CBEs), a framework that generalizes existing CBMs along two dimensions: the number of experts and the functional form of each expert, exposing an underexplored region of the design space. We investigate this region by instantiating two novel models: Linear M-CBE, which learns a finite set of linear expressions, and Symbolic M-CBE, which leverages symbolic regression to discover expert functions from data under user-specified operator vocabularies. Empirical evaluation demonstrates that varying the mixture size and functional form provides a robust framework for navigating the accuracy-interpretability trade-off, adapting to different user and task needs.

---

## 论文详细总结（自动生成）

这篇论文介绍了一种名为**概念瓶颈专家混合（Mixture of Concept Bottleneck Experts, M-CBEs）**的新型架构，旨在解决传统概念瓶颈模型（CBM）在预测精度与可解释性之间的权衡难题。

以下是对该论文的结构化深入总结：

### 1. 核心问题与整体含义（研究动机和背景）
*   **研究动机**：虽然 CBM 通过引入中间“概念层”提高了模型透明度，但现有的 CBM 往往将任务预测器限制为单一的、全局的线性或布尔函数。这种“一刀切”的设计限制了模型的表达能力（难以捕捉复杂的非线性关系），且无法适应不同用户对可解释性的个性化需求（例如，物理学家可能需要三角函数，而普通用户可能只需要加减法）。
*   **核心问题**：如何在保持语义透明度的同时，提升任务预测器的灵活性和准确性？

### 2. 方法论：核心思想与关键技术
*   **核心思想**：将任务预测器建模为多个**专家（Experts）**的混合，每个专家拥有可自定义的**函数形式（Functional Form）**。
*   **关键技术细节**：
    *   **概率图模型**：模型由概念编码器 $p(c|x)$、专家选择器 $p(m|x)$ 和任务预测器 $p(y|c, t_m)$ 组成。输入 $x$ 首先被映射到概念 $c$，同时选择器决定使用哪个专家 $m$。
    *   **表达式树（Expression Trees）**：使用有向无环图（DAG）表示数学表达式，节点包括概念变量、算子（如 $+$, $\times$, $\sin$, $\exp$）和可学习参数。
    *   **两种实例化模型**：
        1.  **Linear M-CBE**：学习一组有限的线性表达式，适用于高维分类任务。
        2.  **Symbolic M-CBE**：利用**符号回归（Symbolic Regression）**自动从数据中发现数学公式。
    *   **Symbolic M-CBE 的三阶段训练流程**：
        1.  联合训练概念编码器、选择器和作为占位符的 MLP 专家。
        2.  使用符号回归（PySR 库）从训练好的 MLP 中蒸馏出符号表达式。
        3.  将符号表达式嵌入模型，并对参数进行端到端的微调。

### 3. 实验设计
*   **数据集**：
    *   **合成数据**：MNIST-Arith（算术运算）、dSprites-Exp（指数函数）、Pendulum（单摆物理位置）。
    *   **真实数据**：MAWPS（数学应用题）、AWA2（动物分类）、CUB-200（鸟类分类）、CIFAR-10（标签缺失场景）。
*   **Benchmark 与对比方法**：
    *   对比了标准 CBM、CEM（概念嵌入模型）、DCR/LICEM（局部解释模型）、CMR（布尔逻辑模型）以及纯黑盒 DNN。
*   **评估维度**：准确性（MAE/错误率）、可解释性（节点数/深度）、干预能力（Intervenability）和适应性。

### 4. 资源与算力
*   **算力说明**：论文中**未明确列出**具体的 GPU 型号、数量或总训练时长。
*   **实现细节**：提到使用了 PyTorch Lightning 框架，优化器为 AdamW，符号回归部分使用了 PySR 库（配置为 40 个种群，进化 100 代）。

### 5. 实验数量与充分性
*   **实验规模**：在 9 个不同的数据集上进行了测试，涵盖了回归和分类任务。
*   **充分性**：
    *   每组实验均运行了 **5 个随机种子**并提供了 95% 的置信区间，结果具有统计意义。
    *   进行了**消融实验**，探讨了算子集合大小、概念瓶颈规模对性能的影响。
    *   对比了 KAN（Kolmogorov-Arnold Networks）作为符号预测器的效果。
    *   实验设计较为客观，通过 Pareto 前沿（Pareto Frontier）展示了准确性与复杂性的权衡，避免了单一指标的片面性。

### 6. 主要结论与发现
*   **设计空间的重要性**：通过调整专家数量和函数形式，M-CBE 能够找到比现有模型更好的准确性-可解释性平衡点。
*   **代数形式的优越性**：在处理高维概念空间时，线性或符号专家比布尔逻辑专家更稳健（准确率提升高达 65%）。
*   **多专家的补偿作用**：当概念集不完整或任务逻辑随输入变化时，多个专家能显著提升性能。
*   **公式发现**：Symbolic M-CBE 能够准确还原 Pendulum 等数据集背后的物理公式（如 $\sin$ 函数）。
*   **干预响应**：符号专家对人类干预（修正预测概念）的响应最接近理想状态。

### 7. 优点与亮点
*   **灵活性**：框架通用性强，可以涵盖现有的多种 CBM 变体。
*   **后验适应性**：Symbolic M-CBE 支持在不重新训练编码器的情况下，根据用户需求更改算子库（如从复杂公式切换到简单加减法）。
*   **全局可解释性**：与生成输入相关解释的模型不同，M-CBE 提供有限数量的、可供人类审查的全局公式。

### 8. 不足与局限
*   **选择器的黑盒性**：虽然专家函数是透明的，但负责路由的“选择器”网络仍然是一个黑盒，用户难以理解为何某个样本被分配给特定专家。
*   **计算开销**：符号回归阶段（PySR）涉及启发式搜索，计算成本较高，难以扩展到极大规模的算子库。
*   **超参数依赖**：专家数量 $M$ 需要预先指定，目前缺乏自动确定最优专家数量的机制。

（完）
