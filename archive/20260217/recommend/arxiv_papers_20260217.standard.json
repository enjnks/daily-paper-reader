{
  "mode": "standard",
  "generated_at": "2026-02-17T04:34:53.368926+00:00",
  "stats": {
    "mode": "standard",
    "tag_count": 1,
    "deep_divecandidates": 1,
    "deep_cap": 6,
    "deep_selected": 1,
    "quick_candidates": 3,
    "quick_skim_target": 11,
    "quick_selected": 3
  },
  "deep_dive": [
    {
      "id": "2602.14670v1",
      "title": "FactorMiner: A Self-Evolving Agent with Skills and Experience Memory for Financial Alpha Discovery",
      "abstract": "Formulaic alpha factor mining is a critical yet challenging task in quantitative investment, characterized by a vast search space and the need for domain-informed, interpretable signals. However, finding novel signals becomes increasingly difficult as the library grows due to high redundancy. We propose FactorMiner, a lightweight and flexible self-evolving agent framework designed to navigate this complex landscape through continuous knowledge accumulation. FactorMiner combines a Modular Skill Architecture that encapsulates systematic financial evaluation into executable tools with a structured Experience Memory that distills historical mining trials into actionable insights (successful patterns and failure constraints). By instantiating the Ralph Loop paradigm -- retrieve, generate, evaluate, and distill -- FactorMiner iteratively uses memory priors to guide exploration, reducing redundant search while focusing on promising directions. Experiments on multiple datasets across different assets and Markets show that FactorMiner constructs a diverse library of high-quality factors with competitive performance, while maintaining low redundancy among factors as the library scales. Overall, FactorMiner provides a practical approach to scalable discovery of interpretable formulaic alpha factors under the \"Correlation Red Sea\" constraint.",
      "authors": [
        "Yanlong Wang",
        "Jian Xu",
        "Hongkang Zhang",
        "Shao-Lun Huang",
        "Danny Dongning Sun",
        "Xiao-Ping Zhang"
      ],
      "primary_category": "q-fin.TR",
      "categories": [
        "q-fin.TR",
        "cs.MA"
      ],
      "published": "2026-02-16 11:48:52+00:00",
      "link": "https://arxiv.org/pdf/2602.14670v1",
      "tags": [
        "keyword:SR"
      ],
      "llm_score": 8.0,
      "llm_evidence_en": "Formulaic alpha factor mining for financial discovery",
      "llm_evidence_cn": "金融发现中的公式化 Alpha 因子挖掘",
      "llm_evidence": "金融发现中的公式化 Alpha 因子挖掘",
      "llm_tldr_en": "A self-evolving agent framework for mining interpretable formulaic signals in quantitative investment.",
      "llm_tldr_cn": "一种用于在量化投资中挖掘可解释公式化信号的自进化智能体框架。",
      "llm_tldr": "一种用于在量化投资中挖掘可解释公式化信号的自进化智能体框架。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ]
    }
  ],
  "quick_skim": [
    {
      "id": "2602.13769v1",
      "title": "OR-Agent: Bridging Evolutionary Search and Structured Research for Automated Algorithm Discovery",
      "abstract": "Automating scientific discovery in complex, experiment-driven domains requires more than iterative mutation of programs; it demands structured hypothesis management, environment interaction, and principled reflection. We present OR-Agent, a configurable multi-agent research framework designed for automated exploration in rich experimental environments. OR-Agent organizes research as a structured tree-based workflow that explicitly models branching hypothesis generation and systematic backtracking, enabling controlled management of research trajectories beyond simple mutation-crossover loops. At its core, we introduce an evolutionary-systematic ideation mechanism that unifies evolutionary selection of research starting points, comprehensive research plan generation, and coordinated exploration within a research tree. We further propose a hierarchical optimization-inspired reflection system: short-term experimental reflection operates as a form of verbal gradient providing immediate corrective signals; long-term reflection accumulates cross-experiment insights as verbal momentum; and memory compression serves as a regularization mechanism analogous to weight decay, preserving essential signals while mitigating drift. Together, these components form a principled architecture governing research dynamics. We conduct extensive experiments across classical combinatorial optimization benchmarks-including traveling salesman, capacitated vehicle routing, bin packing, orienteering, and multiple knapsack problems-as well as simulation-based cooperative driving scenarios. Results demonstrate that OR-Agent outperforms strong evolutionary baselines while providing a general, extensible, and inspectable framework for AI-assisted scientific discovery. OR-Agent source code and experiments data are publicly available at https://github.com/qiliuchn/OR-Agent.",
      "authors": [
        "Qi Liu",
        "Wanjing Ma"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.NE"
      ],
      "published": "2026-02-14 13:32:03+00:00",
      "link": "https://arxiv.org/pdf/2602.13769v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "automated algorithm discovery and evolutionary search",
      "llm_evidence_cn": "自动算法发现与进化搜索",
      "llm_evidence": "自动算法发现与进化搜索",
      "llm_tldr_en": "Presents a framework for automated algorithm discovery using evolutionary search, relevant to SR methods.",
      "llm_tldr_cn": "提出一个利用进化搜索进行自动算法发现的框架，与符号回归方法论相关。",
      "llm_tldr": "提出一个利用进化搜索进行自动算法发现的框架，与符号回归方法论相关。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.13864v1",
      "title": "Evolving Multi-Channel Confidence-Aware Activation Functions for Missing Data with Channel Propagation",
      "abstract": "Learning in the presence of missing data can result in biased predictions and poor generalizability, among other difficulties, which data imputation methods only partially address. In neural networks, activation functions significantly affect performance yet typical options (e.g., ReLU, Swish) operate only on feature values and do not account for missingness indicators or confidence scores. We propose Three-Channel Evolved Activations (3C-EA), which we evolve using Genetic Programming to produce multivariate activation functions f(x, m, c) in the form of trees that take (i) the feature value x, (ii) a missingness indicator m, and (iii) an imputation confidence score c. To make these activations useful beyond the input layer, we introduce ChannelProp, an algorithm that deterministically propagates missingness and confidence values via linear layers based on weight magnitudes, retaining reliability signals throughout the network. We evaluate 3C-EA and ChannelProp on datasets with natural and injected (MCAR/MAR/MNAR) missingness at multiple rates under identical preprocessing and splits. Results indicate that integrating missingness and confidence inputs into the activation search improves classification performance under missingness.",
      "authors": [
        "Naeem Shahabi Sani",
        "Ferial Najiantabriz",
        "Shayan Shafaei",
        "Dean F. Hougen"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.LG"
      ],
      "published": "2026-02-14 19:52:10+00:00",
      "link": "https://arxiv.org/pdf/2602.13864v1",
      "tags": [
        "keyword:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Uses Genetic Programming to evolve multivariate activation functions in tree form",
      "llm_evidence_cn": "使用遗传规划演化树状结构的多元激活函数",
      "llm_evidence": "使用遗传规划演化树状结构的多元激活函数",
      "llm_tldr_en": "Evolves tree-based activation functions using Genetic Programming, a core technique in Symbolic Regression.",
      "llm_tldr_cn": "利用符号回归的核心技术遗传规划，演化出处理缺失数据的树状激活函数。",
      "llm_tldr": "利用符号回归的核心技术遗传规划，演化出处理缺失数据的树状激活函数。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.14573v1",
      "title": "Polar: An Algebraic Analyzer for (Probabilistic) Loops",
      "abstract": "We present the Polar framework for fully automating the analysis of classical and probabilistic loops using algebraic reasoning. The central theme in Polar comes with handling algebraic recurrences that precisely capture the loop semantics. To this end, our work implements a variety of techniques to compute exact closed-forms of recurrences over higher-order moments of variables, infer invariants, and derive loop sensitivities with respect to unknown parameters. Polar can analyze probabilistic loops containing if-statements, polynomial arithmetic, and common probability distributions. By translating loop analysis into linear recurrence solving, Polar uses the derived closed-forms of recurrences to compute the strongest polynomial invariant or to infer parameter sensitivity. Polar is both sound and complete within well-defined programming model restrictions. Lifting any of these restrictions results in significant hardness limits of computation. To overcome computational burdens for the sake of efficiency, Polar also provides incomplete but sound techniques to compute moments of combinations of variables.",
      "authors": [
        "Marcel Moosbrugger",
        "Julian Müllner",
        "Ezio Bartocci",
        "Laura Kovács"
      ],
      "primary_category": "cs.PL",
      "categories": [
        "cs.PL"
      ],
      "published": "2026-02-16 09:05:42+00:00",
      "link": "https://arxiv.org/pdf/2602.14573v1",
      "tags": [
        "query:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Algebraic reasoning for loop analysis and closed-form recurrences",
      "llm_evidence_cn": "循环分析和闭式递归的代数推理",
      "llm_evidence": "循环分析和闭式递归的代数推理",
      "llm_tldr_en": "A framework for automating the analysis of probabilistic loops using algebraic recurrence solving.",
      "llm_tldr_cn": "一个利用代数递归求解自动分析概率循环的框架。",
      "llm_tldr": "一个利用代数递归求解自动分析概率循环的框架。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ],
      "quick_tier": "6"
    }
  ]
}