{
  "mode": "standard",
  "generated_at": "2026-02-05T04:29:57.300798+00:00",
  "stats": {
    "mode": "standard",
    "tag_count": 1,
    "deep_divecandidates": 2,
    "deep_cap": 6,
    "deep_selected": 2,
    "quick_candidates": 2,
    "quick_skim_target": 11,
    "quick_selected": 2
  },
  "deep_dive": [
    {
      "id": "2602.04492v1",
      "title": "Discovering Mechanistic Models of Neural Activity: System Identification in an in Silico Zebrafish",
      "abstract": "Constructing mechanistic models of neural circuits is a fundamental goal of neuroscience, yet verifying such models is limited by the lack of ground truth. To rigorously test model discovery, we establish an in silico testbed using neuromechanical simulations of a larval zebrafish as a transparent ground truth. We find that LLM-based tree search autonomously discovers predictive models that significantly outperform established forecasting baselines. Conditioning on sensory drive is necessary but not sufficient for faithful system identification, as models exploit statistical shortcuts. Structural priors prove essential for enabling robust out-of-distribution generalization and recovery of interpretable mechanistic models. Our insights provide guidance for modeling real-world neural recordings and offer a broader template for AI-driven scientific discovery.",
      "authors": [
        "Jan-Matthis Lueckmann",
        "Viren Jain",
        "Michał Januszewski"
      ],
      "primary_category": "q-bio.NC",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-04 12:33:29+00:00",
      "link": "https://arxiv.org/pdf/2602.04492v1",
      "tags": [
        "keyword:SR"
      ],
      "llm_score": 8.0,
      "llm_evidence_en": "LLM-based tree search for discovering interpretable mechanistic models",
      "llm_evidence_cn": "基于大模型的树搜索用于发现可解释的机制模型",
      "llm_evidence": "基于大模型的树搜索用于发现可解释的机制模型",
      "llm_tldr_en": "Uses LLM-based tree search to discover interpretable mechanistic models in neuroscience, aligning with SR goals.",
      "llm_tldr_cn": "利用基于大模型的树搜索在神经科学中发现可解释的机制模型，符合符号回归的目标。",
      "llm_tldr": "利用基于大模型的树搜索在神经科学中发现可解释的机制模型，符合符号回归的目标。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ]
    },
    {
      "id": "2602.04529v1",
      "title": "Landscape-aware Automated Algorithm Design: An Efficient Framework for Real-world Optimization",
      "abstract": "The advent of Large Language Models (LLMs) has opened new frontiers in automated algorithm design, giving rise to numerous powerful methods. However, these approaches retain critical limitations: they require extensive evaluation of the target problem to guide the search process, making them impractical for real-world optimization tasks, where each evaluation consumes substantial computational resources. This research proposes an innovative and efficient framework that decouples algorithm discovery from high-cost evaluation. Our core innovation lies in combining a Genetic Programming (GP) function generator with an LLM-driven evolutionary algorithm designer. The evolutionary direction of the GP-based function generator is guided by the similarity between the landscape characteristics of generated proxy functions and those of real-world problems, ensuring that algorithms discovered via proxy functions exhibit comparable performance on real-world problems. Our method enables deep exploration of the algorithmic space before final validation while avoiding costly real-world evaluations. We validated the framework's efficacy across multiple real-world problems, demonstrating its ability to discover high-performance algorithms while substantially reducing expensive evaluations. This approach shows a path to apply LLM-based automated algorithm design to computationally intensive real-world optimization challenges.",
      "authors": [
        "Haoran Yin",
        "Shuaiqun Pan",
        "Zhao Wei",
        "Jian Cheng Wong",
        "Yew-Soon Ong",
        "Anna V. Kononova",
        "Thomas Bäck",
        "Niki van Stein"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-02-04 13:18:45+00:00",
      "link": "https://arxiv.org/pdf/2602.04529v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 8.0,
      "llm_evidence_en": "Genetic Programming function generator for algorithm design",
      "llm_evidence_cn": "用于算法设计的遗传规划函数生成器",
      "llm_evidence": "用于算法设计的遗传规划函数生成器",
      "llm_tldr_en": "Combines Genetic Programming with LLMs for automated algorithm design, a core methodology in symbolic regression.",
      "llm_tldr_cn": "结合遗传规划与大模型进行自动算法设计，这是符号回归的核心方法论。",
      "llm_tldr": "结合遗传规划与大模型进行自动算法设计，这是符号回归的核心方法论。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ]
    }
  ],
  "quick_skim": [
    {
      "id": "2602.04114v1",
      "title": "Turning mechanistic models into forecasters by using machine learning",
      "abstract": "The equations of complex dynamical systems may not be identified by expert knowledge, especially if the underlying mechanisms are unknown. Data-driven discovery methods address this challenge by inferring governing equations from time-series data using a library of functions constructed from the measured variables. However, these methods typically assume time-invariant coefficients, which limits their ability to capture evolving system dynamics. To overcome this limitation, we allow some of the parameters to vary over time, learn their temporal evolution directly from data, and infer a system of equations that incorporates both constant and time-varying parameters. We then transform this framework into a forecasting model by predicting the time-varying parameters and substituting these predictions into the learned equations. The model is validated using datasets for Susceptible-Infected-Recovered, Consumer--Resource, greenhouse gas concentration, and Cyanobacteria cell count. By dynamically adapting to temporal shifts, our proposed model achieved a mean absolute error below 3\\% for learning a time series and below 6\\% for forecasting up to a month ahead. We additionally compare forecasting performance against CNN-LSTM and Gradient Boosting Machine (GBM), and show that our model outperforms these methods across most datasets. Our findings demonstrate that integrating time-varying parameters into data-driven discovery of differential equations improves both modeling accuracy and forecasting performance.",
      "authors": [
        "Amit K. Chakraborty",
        "Hao Wang",
        "Pouria Ramazi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.DS"
      ],
      "published": "2026-02-04 01:00:08+00:00",
      "link": "https://arxiv.org/pdf/2602.04114v1",
      "tags": [
        "keyword:SR"
      ],
      "llm_score": 7.0,
      "llm_evidence_en": "Data-driven discovery of governing equations from time-series",
      "llm_evidence_cn": "从时间序列中进行数据驱动的控制方程发现",
      "llm_evidence": "从时间序列中进行数据驱动的控制方程发现",
      "llm_tldr_en": "Proposes a method to infer governing equations with time-varying parameters from data, similar to symbolic regression.",
      "llm_tldr_cn": "提出一种从数据中推断具有时变参数的控制方程的方法，与符号回归目标高度一致。",
      "llm_tldr": "提出一种从数据中推断具有时变参数的控制方程的方法，与符号回归目标高度一致。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2602.04006v1",
      "title": "Rational ANOVA Networks",
      "abstract": "Deep neural networks typically treat nonlinearities as fixed primitives (e.g., ReLU), limiting both interpretability and the granularity of control over the induced function class. While recent additive models (like KANs) attempt to address this using splines, they often suffer from computational inefficiency and boundary instability. We propose the Rational-ANOVA Network (RAN), a foundational architecture grounded in functional ANOVA decomposition and Padé-style rational approximation. RAN models f(x) as a composition of main effects and sparse pairwise interactions, where each component is parameterized by a stable, learnable rational unit. Crucially, we enforce a strictly positive denominator, which avoids poles and numerical instability while capturing sharp transitions and near-singular behaviors more efficiently than polynomial bases. This ANOVA structure provides an explicit low-order interaction bias for data efficiency and interpretability, while the rational parameterization significantly improves extrapolation. Across controlled function benchmarks and vision classification tasks (e.g., CIFAR-10) under matched parameter and compute budgets, RAN matches or surpasses parameter-matched MLPs and learnable-activation baselines, with better stability and throughput. Code is available at https://github.com/jushengzhang/Rational-ANOVA-Networks.git.",
      "authors": [
        "Jusheng Zhang",
        "Ningyuan Liu",
        "Qinhan Lyu",
        "Jing Yang",
        "Keze Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-03 20:46:00+00:00",
      "link": "https://arxiv.org/pdf/2602.04006v1",
      "tags": [
        "keyword:SR",
        "query:SR"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Interpretable functional decomposition and rational approximation",
      "llm_evidence_cn": "可解释的函数分解与有理逼近",
      "llm_evidence": "可解释的函数分解与有理逼近",
      "llm_tldr_en": "Introduces Rational-ANOVA Networks for interpretable function approximation using learnable rational units.",
      "llm_tldr_cn": "引入Rational-ANOVA网络，利用可学习的有理单元进行可解释的函数逼近。",
      "llm_tldr": "引入Rational-ANOVA网络，利用可学习的有理单元进行可解释的函数逼近。",
      "llm_tags": [
        "keyword:SR",
        "query:SR"
      ],
      "quick_tier": "6"
    }
  ]
}